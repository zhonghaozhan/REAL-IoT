{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Hjc3iIihKLn-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from dgl.data import DGLDataset\n",
        "import dgl\n",
        "import time\n",
        "import networkx as nx\n",
        "import category_encoders as ce\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "from typing import *\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "import socket\n",
        "import struct\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "SvWHb_BpKsLq"
      },
      "outputs": [],
      "source": [
        "file_name = \"/media/ssd/test/standardized-datasets/combined/combined_netflow_reduced.csv\"\n",
        "data = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "fqly1y-LMwYS",
        "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "0    3797826\n",
              "1    1018415\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3t4OREvSM33h"
      },
      "outputs": [],
      "source": [
        "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
        "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
        "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
        "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "bTtHq0XqNXxI"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNIP-8zNkn9",
        "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['DDoS', 'DoS', 'Reconnaissance', 'Benign', 'Theft',\n",
              "       'DDOS attack-HOIC', 'DoS attacks-Hulk', 'SSH-Bruteforce',\n",
              "       'Infilteration', 'DDoS attacks-LOIC-HTTP',\n",
              "       'DoS attacks-SlowHTTPTest', 'Bot', 'FTP-BruteForce',\n",
              "       'DoS attacks-GoldenEye', 'Brute Force -XSS',\n",
              "       'DDOS attack-LOIC-UDP', 'SQL Injection', 'DoS attacks-Slowloris',\n",
              "       'Brute Force -Web', 'Exploits', 'Generic', 'Fuzzers', 'Backdoor',\n",
              "       'Shellcode', 'Worms', 'Analysis'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Attack.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AlPa58fVN7gB"
      },
      "outputs": [],
      "source": [
        "data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "lcfAP6ViOp-J",
        "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>Label</th>\n",
              "      <th>flow_id</th>\n",
              "      <th>dataset_source</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attack</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Backdoor</th>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>...</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>...</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "      <td>379783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bot</th>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>...</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "      <td>7155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Brute Force -Web</th>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>...</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "      <td>107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Brute Force -XSS</th>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>...</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "      <td>93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDOS attack-HOIC</th>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>...</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "      <td>21617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDOS attack-LOIC-UDP</th>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>...</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "      <td>106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS</th>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>...</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS attacks-LOIC-HTTP</th>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>...</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "      <td>6146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS</th>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>...</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "      <td>15585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS attacks-GoldenEye</th>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>...</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "      <td>1386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS attacks-Hulk</th>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>...</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "      <td>8653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS attacks-SlowHTTPTest</th>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>...</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "      <td>706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS attacks-Slowloris</th>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>...</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "      <td>476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exploits</th>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>...</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FTP-BruteForce</th>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>...</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "      <td>1297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fuzzers</th>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>...</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Generic</th>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>...</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Infilteration</th>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>...</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "      <td>5818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reconnaissance</th>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>...</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "      <td>3636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SQL Injection</th>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>...</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SSH-Bruteforce</th>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>...</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "      <td>4749</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shellcode</th>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>...</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Theft</th>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>...</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worms</th>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>26 rows Ã— 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                          IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  \\\n",
              "Attack                                                                       \n",
              "Analysis                            230            230       230       230   \n",
              "Backdoor                            217            217       217       217   \n",
              "Benign                           379783         379783    379783    379783   \n",
              "Bot                                7155           7155      7155      7155   \n",
              "Brute Force -Web                    107            107       107       107   \n",
              "Brute Force -XSS                     93             93        93        93   \n",
              "DDOS attack-HOIC                  21617          21617     21617     21617   \n",
              "DDOS attack-LOIC-UDP                106            106       106       106   \n",
              "DDoS                              16499          16499     16499     16499   \n",
              "DDoS attacks-LOIC-HTTP             6146           6146      6146      6146   \n",
              "DoS                               15585          15585     15585     15585   \n",
              "DoS attacks-GoldenEye              1386           1386      1386      1386   \n",
              "DoS attacks-Hulk                   8653           8653      8653      8653   \n",
              "DoS attacks-SlowHTTPTest            706            706       706       706   \n",
              "DoS attacks-Slowloris               476            476       476       476   \n",
              "Exploits                           3155           3155      3155      3155   \n",
              "FTP-BruteForce                     1297           1297      1297      1297   \n",
              "Fuzzers                            2231           2231      2231      2231   \n",
              "Generic                            1656           1656      1656      1656   \n",
              "Infilteration                      5818           5818      5818      5818   \n",
              "Reconnaissance                     3636           3636      3636      3636   \n",
              "SQL Injection                        43             43        43        43   \n",
              "SSH-Bruteforce                     4749           4749      4749      4749   \n",
              "Shellcode                           143            143       143       143   \n",
              "Theft                               122            122       122       122   \n",
              "Worms                                16             16        16        16   \n",
              "\n",
              "                          IN_BYTES  IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  \\\n",
              "Attack                                                                        \n",
              "Analysis                       230      230        230       230        230   \n",
              "Backdoor                       217      217        217       217        217   \n",
              "Benign                      379783   379783     379783    379783     379783   \n",
              "Bot                           7155     7155       7155      7155       7155   \n",
              "Brute Force -Web               107      107        107       107        107   \n",
              "Brute Force -XSS                93       93         93        93         93   \n",
              "DDOS attack-HOIC             21617    21617      21617     21617      21617   \n",
              "DDOS attack-LOIC-UDP           106      106        106       106        106   \n",
              "DDoS                         16499    16499      16499     16499      16499   \n",
              "DDoS attacks-LOIC-HTTP        6146     6146       6146      6146       6146   \n",
              "DoS                          15585    15585      15585     15585      15585   \n",
              "DoS attacks-GoldenEye         1386     1386       1386      1386       1386   \n",
              "DoS attacks-Hulk              8653     8653       8653      8653       8653   \n",
              "DoS attacks-SlowHTTPTest       706      706        706       706        706   \n",
              "DoS attacks-Slowloris          476      476        476       476        476   \n",
              "Exploits                      3155     3155       3155      3155       3155   \n",
              "FTP-BruteForce                1297     1297       1297      1297       1297   \n",
              "Fuzzers                       2231     2231       2231      2231       2231   \n",
              "Generic                       1656     1656       1656      1656       1656   \n",
              "Infilteration                 5818     5818       5818      5818       5818   \n",
              "Reconnaissance                3636     3636       3636      3636       3636   \n",
              "SQL Injection                   43       43         43        43         43   \n",
              "SSH-Bruteforce                4749     4749       4749      4749       4749   \n",
              "Shellcode                      143      143        143       143        143   \n",
              "Theft                          122      122        122       122        122   \n",
              "Worms                           16       16         16        16         16   \n",
              "\n",
              "                          CLIENT_TCP_FLAGS  ...  TCP_WIN_MAX_OUT  ICMP_TYPE  \\\n",
              "Attack                                      ...                               \n",
              "Analysis                               230  ...              230        230   \n",
              "Backdoor                               217  ...              217        217   \n",
              "Benign                              379783  ...           379783     379783   \n",
              "Bot                                   7155  ...             7155       7155   \n",
              "Brute Force -Web                       107  ...              107        107   \n",
              "Brute Force -XSS                        93  ...               93         93   \n",
              "DDOS attack-HOIC                     21617  ...            21617      21617   \n",
              "DDOS attack-LOIC-UDP                   106  ...              106        106   \n",
              "DDoS                                 16499  ...            16499      16499   \n",
              "DDoS attacks-LOIC-HTTP                6146  ...             6146       6146   \n",
              "DoS                                  15585  ...            15585      15585   \n",
              "DoS attacks-GoldenEye                 1386  ...             1386       1386   \n",
              "DoS attacks-Hulk                      8653  ...             8653       8653   \n",
              "DoS attacks-SlowHTTPTest               706  ...              706        706   \n",
              "DoS attacks-Slowloris                  476  ...              476        476   \n",
              "Exploits                              3155  ...             3155       3155   \n",
              "FTP-BruteForce                        1297  ...             1297       1297   \n",
              "Fuzzers                               2231  ...             2231       2231   \n",
              "Generic                               1656  ...             1656       1656   \n",
              "Infilteration                         5818  ...             5818       5818   \n",
              "Reconnaissance                        3636  ...             3636       3636   \n",
              "SQL Injection                           43  ...               43         43   \n",
              "SSH-Bruteforce                        4749  ...             4749       4749   \n",
              "Shellcode                              143  ...              143        143   \n",
              "Theft                                  122  ...              122        122   \n",
              "Worms                                   16  ...               16         16   \n",
              "\n",
              "                          ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  \\\n",
              "Attack                                                                   \n",
              "Analysis                             230           230             230   \n",
              "Backdoor                             217           217             217   \n",
              "Benign                            379783        379783          379783   \n",
              "Bot                                 7155          7155            7155   \n",
              "Brute Force -Web                     107           107             107   \n",
              "Brute Force -XSS                      93            93              93   \n",
              "DDOS attack-HOIC                   21617         21617           21617   \n",
              "DDOS attack-LOIC-UDP                 106           106             106   \n",
              "DDoS                               16499         16499           16499   \n",
              "DDoS attacks-LOIC-HTTP              6146          6146            6146   \n",
              "DoS                                15585         15585           15585   \n",
              "DoS attacks-GoldenEye               1386          1386            1386   \n",
              "DoS attacks-Hulk                    8653          8653            8653   \n",
              "DoS attacks-SlowHTTPTest             706           706             706   \n",
              "DoS attacks-Slowloris                476           476             476   \n",
              "Exploits                            3155          3155            3155   \n",
              "FTP-BruteForce                      1297          1297            1297   \n",
              "Fuzzers                             2231          2231            2231   \n",
              "Generic                             1656          1656            1656   \n",
              "Infilteration                       5818          5818            5818   \n",
              "Reconnaissance                      3636          3636            3636   \n",
              "SQL Injection                         43            43              43   \n",
              "SSH-Bruteforce                      4749          4749            4749   \n",
              "Shellcode                            143           143             143   \n",
              "Theft                                122           122             122   \n",
              "Worms                                 16            16              16   \n",
              "\n",
              "                          DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE   Label  \\\n",
              "Attack                                                                   \n",
              "Analysis                             230                   230     230   \n",
              "Backdoor                             217                   217     217   \n",
              "Benign                            379783                379783  379783   \n",
              "Bot                                 7155                  7155    7155   \n",
              "Brute Force -Web                     107                   107     107   \n",
              "Brute Force -XSS                      93                    93      93   \n",
              "DDOS attack-HOIC                   21617                 21617   21617   \n",
              "DDOS attack-LOIC-UDP                 106                   106     106   \n",
              "DDoS                               16499                 16499   16499   \n",
              "DDoS attacks-LOIC-HTTP              6146                  6146    6146   \n",
              "DoS                                15585                 15585   15585   \n",
              "DoS attacks-GoldenEye               1386                  1386    1386   \n",
              "DoS attacks-Hulk                    8653                  8653    8653   \n",
              "DoS attacks-SlowHTTPTest             706                   706     706   \n",
              "DoS attacks-Slowloris                476                   476     476   \n",
              "Exploits                            3155                  3155    3155   \n",
              "FTP-BruteForce                      1297                  1297    1297   \n",
              "Fuzzers                             2231                  2231    2231   \n",
              "Generic                             1656                  1656    1656   \n",
              "Infilteration                       5818                  5818    5818   \n",
              "Reconnaissance                      3636                  3636    3636   \n",
              "SQL Injection                         43                    43      43   \n",
              "SSH-Bruteforce                      4749                  4749    4749   \n",
              "Shellcode                            143                   143     143   \n",
              "Theft                                122                   122     122   \n",
              "Worms                                 16                    16      16   \n",
              "\n",
              "                          flow_id  dataset_source  \n",
              "Attack                                             \n",
              "Analysis                      230             230  \n",
              "Backdoor                      217             217  \n",
              "Benign                     379783          379783  \n",
              "Bot                          7155            7155  \n",
              "Brute Force -Web              107             107  \n",
              "Brute Force -XSS               93              93  \n",
              "DDOS attack-HOIC            21617           21617  \n",
              "DDOS attack-LOIC-UDP          106             106  \n",
              "DDoS                        16499           16499  \n",
              "DDoS attacks-LOIC-HTTP       6146            6146  \n",
              "DoS                         15585           15585  \n",
              "DoS attacks-GoldenEye        1386            1386  \n",
              "DoS attacks-Hulk             8653            8653  \n",
              "DoS attacks-SlowHTTPTest      706             706  \n",
              "DoS attacks-Slowloris         476             476  \n",
              "Exploits                     3155            3155  \n",
              "FTP-BruteForce               1297            1297  \n",
              "Fuzzers                      2231            2231  \n",
              "Generic                      1656            1656  \n",
              "Infilteration                5818            5818  \n",
              "Reconnaissance               3636            3636  \n",
              "SQL Injection                  43              43  \n",
              "SSH-Bruteforce               4749            4749  \n",
              "Shellcode                     143             143  \n",
              "Theft                         122             122  \n",
              "Worms                          16              16  \n",
              "\n",
              "[26 rows x 44 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.groupby(by=\"Attack\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FqRx5xCPOuv8"
      },
      "outputs": [],
      "source": [
        "X = data.drop(columns=[\"Attack\", \"Label\"])\n",
        "y = data[[\"Attack\", \"Label\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=13, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bPfakXplPGGx"
      },
      "outputs": [],
      "source": [
        "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
        "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
        "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
        "                                  'FTP_COMMAND_RET_CODE'])\n",
        "encoder.fit(X_train, y_train.Label)\n",
        "\n",
        "# Transform on training set\n",
        "X_train = encoder.transform(X_train)\n",
        "\n",
        "# Transform on testing set\n",
        "X_test = encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ibyOfV-8PouK"
      },
      "outputs": [],
      "source": [
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'dataset_source' in X_train.columns:\n",
        "    X_train = X_train.drop(columns=['dataset_source'])\n",
        "if 'dataset_source' in X_test.columns:\n",
        "    X_test = X_test.drop(columns=['dataset_source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "asDnsSIWPee0"
      },
      "outputs": [],
      "source": [
        "scaler = Normalizer()\n",
        "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
        "scaler.fit(X_train[cols_to_norm])\n",
        "\n",
        "# Transform on training set\n",
        "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
        "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
        "\n",
        "# Transform on testing set\n",
        "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
        "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
        "\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "test = pd.concat([X_test, y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "hErQbsnrPluV",
        "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>flow_id</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1678536</th>\n",
              "      <td>18.218.11.51</td>\n",
              "      <td>172.31.69.28</td>\n",
              "      <td>4.716756e-08</td>\n",
              "      <td>1.352251e-07</td>\n",
              "      <td>0.000106</td>\n",
              "      <td>1.018746e-06</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>1.018746e-06</td>\n",
              "      <td>1.511850e-07</td>\n",
              "      <td>1.236520e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.013353</td>\n",
              "      <td>0.005477</td>\n",
              "      <td>6.053687e-08</td>\n",
              "      <td>6.053757e-08</td>\n",
              "      <td>5.319932e-08</td>\n",
              "      <td>5.320146e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.695634e-08</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>[4.7167564923371754e-08, 1.3522507470442058e-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3802830</th>\n",
              "      <td>59.166.0.5</td>\n",
              "      <td>149.171.126.4</td>\n",
              "      <td>1.554257e-08</td>\n",
              "      <td>3.024266e-09</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>1.812756e-06</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>1.947034e-06</td>\n",
              "      <td>8.278529e-10</td>\n",
              "      <td>8.277976e-10</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001167</td>\n",
              "      <td>0.001069</td>\n",
              "      <td>1.331946e-09</td>\n",
              "      <td>1.354066e-09</td>\n",
              "      <td>1.753015e-08</td>\n",
              "      <td>1.753085e-08</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.073079e-11</td>\n",
              "      <td>0.255319</td>\n",
              "      <td>[1.5542574692509295e-08, 3.0242658543497837e-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2285590</th>\n",
              "      <td>172.31.64.69</td>\n",
              "      <td>172.31.0.2</td>\n",
              "      <td>4.642899e-08</td>\n",
              "      <td>1.353043e-08</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>5.887329e-07</td>\n",
              "      <td>0.000084</td>\n",
              "      <td>5.887329e-07</td>\n",
              "      <td>4.870199e-08</td>\n",
              "      <td>4.869631e-08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>8.746057e-08</td>\n",
              "      <td>8.746159e-08</td>\n",
              "      <td>5.414639e-08</td>\n",
              "      <td>1.347604e-08</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>6.784011e-08</td>\n",
              "      <td>0.672801</td>\n",
              "      <td>[4.642898567879007e-08, 1.3530425343873105e-08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4792203</th>\n",
              "      <td>59.166.0.5</td>\n",
              "      <td>149.171.126.8</td>\n",
              "      <td>3.231844e-09</td>\n",
              "      <td>6.416912e-10</td>\n",
              "      <td>0.000125</td>\n",
              "      <td>1.954479e-07</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>8.376338e-08</td>\n",
              "      <td>1.392591e-09</td>\n",
              "      <td>1.468150e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>0.000142</td>\n",
              "      <td>8.263405e-11</td>\n",
              "      <td>8.716750e-11</td>\n",
              "      <td>3.645130e-09</td>\n",
              "      <td>3.645277e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.217371e-09</td>\n",
              "      <td>0.066902</td>\n",
              "      <td>[3.2318441136909897e-09, 6.416911557150659e-10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518567</th>\n",
              "      <td>13.58.98.64</td>\n",
              "      <td>172.31.69.25</td>\n",
              "      <td>5.840510e-09</td>\n",
              "      <td>1.210137e-08</td>\n",
              "      <td>0.000081</td>\n",
              "      <td>6.307297e-07</td>\n",
              "      <td>0.000095</td>\n",
              "      <td>5.298130e-07</td>\n",
              "      <td>2.516657e-09</td>\n",
              "      <td>2.653204e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000678</td>\n",
              "      <td>0.000677</td>\n",
              "      <td>7.495960e-09</td>\n",
              "      <td>7.496047e-09</td>\n",
              "      <td>6.587390e-09</td>\n",
              "      <td>6.587655e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.814355e-09</td>\n",
              "      <td>0.013083</td>\n",
              "      <td>[5.840509756442225e-09, 1.2101366649131552e-08...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 43 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        IPV4_SRC_ADDR  IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
              "1678536  18.218.11.51   172.31.69.28  4.716756e-08  1.352251e-07  0.000106   \n",
              "3802830    59.166.0.5  149.171.126.4  1.554257e-08  3.024266e-09  0.000100   \n",
              "2285590  172.31.64.69     172.31.0.2  4.642899e-08  1.353043e-08  0.000038   \n",
              "4792203    59.166.0.5  149.171.126.8  3.231844e-09  6.416912e-10  0.000125   \n",
              "518567    13.58.98.64   172.31.69.25  5.840510e-09  1.210137e-08  0.000081   \n",
              "\n",
              "              IN_PKTS  OUT_BYTES      OUT_PKTS     TCP_FLAGS  \\\n",
              "1678536  1.018746e-06   0.000234  1.018746e-06  1.511850e-07   \n",
              "3802830  1.812756e-06   0.000138  1.947034e-06  8.278529e-10   \n",
              "2285590  5.887329e-07   0.000084  5.887329e-07  4.870199e-08   \n",
              "4792203  1.954479e-07   0.000004  8.376338e-08  1.392591e-09   \n",
              "518567   6.307297e-07   0.000095  5.298130e-07  2.516657e-09   \n",
              "\n",
              "         CLIENT_TCP_FLAGS  ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  \\\n",
              "1678536      1.236520e-07  ...        0.013353         0.005477  6.053687e-08   \n",
              "3802830      8.277976e-10  ...        0.001167         0.001069  1.331946e-09   \n",
              "2285590      4.869631e-08  ...        0.000000         0.000000  8.746057e-08   \n",
              "4792203      1.468150e-09  ...        0.000081         0.000142  8.263405e-11   \n",
              "518567       2.653204e-09  ...        0.000678         0.000677  7.495960e-09   \n",
              "\n",
              "         ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  \\\n",
              "1678536    6.053757e-08  5.319932e-08    5.320146e-08        0.000000   \n",
              "3802830    1.354066e-09  1.753015e-08    1.753085e-08        0.000000   \n",
              "2285590    8.746159e-08  5.414639e-08    1.347604e-08        0.000018   \n",
              "4792203    8.716750e-11  3.645130e-09    3.645277e-09        0.000000   \n",
              "518567     7.496047e-09  6.587390e-09    6.587655e-09        0.000000   \n",
              "\n",
              "         FTP_COMMAND_RET_CODE   flow_id  \\\n",
              "1678536          4.695634e-08  0.342000   \n",
              "3802830          3.073079e-11  0.255319   \n",
              "2285590          6.784011e-08  0.672801   \n",
              "4792203          3.217371e-09  0.066902   \n",
              "518567           5.814355e-09  0.013083   \n",
              "\n",
              "                                                         h  \n",
              "1678536  [4.7167564923371754e-08, 1.3522507470442058e-0...  \n",
              "3802830  [1.5542574692509295e-08, 3.0242658543497837e-0...  \n",
              "2285590  [4.642898567879007e-08, 1.3530425343873105e-08...  \n",
              "4792203  [3.2318441136909897e-09, 6.416911557150659e-10...  \n",
              "518567   [5.840509756442225e-09, 1.2101366649131552e-08...  \n",
              "\n",
              "[5 rows x 43 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d_tLtK4WPtrF"
      },
      "outputs": [],
      "source": [
        "lab_enc = preprocessing.LabelEncoder()\n",
        "lab_enc.fit(data[\"Attack\"])\n",
        "\n",
        "# Transform on training set\n",
        "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
        "\n",
        "# Transform on testing set\n",
        "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8yaicjecP1fZ"
      },
      "outputs": [],
      "source": [
        "# Training graph\n",
        "\n",
        "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "train_g = train_g.to_directed()\n",
        "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
        "train_g.edata['h'].shape[1]])\n",
        "train_g.ndata['h'] = nfeat_weight\n",
        "\n",
        "# Testing graph\n",
        "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "test_g = test_g.to_directed()\n",
        "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
        "test_g.edata['h'].shape[1]])\n",
        "test_g.ndata['h'] = nfeat_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PUV6DgJ9QRaP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import tqdm\n",
        "import gc\n",
        "\n",
        "class SAGELayer(nn.Module):\n",
        "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
        "      super(SAGELayer, self).__init__()\n",
        "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
        "      self.activation = F.relu\n",
        "      self.W_edge = nn.Linear(128 * 2, 256)\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      gain = nn.init.calculate_gain('relu')\n",
        "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
        "\n",
        "    def message_func(self, edges):\n",
        "      return {'m':  edges.data['h']}\n",
        "\n",
        "    def forward(self, g_dgl, nfeats, efeats):\n",
        "      with g_dgl.local_scope():\n",
        "        g = g_dgl\n",
        "        g.ndata['h'] = nfeats\n",
        "        g.edata['h'] = efeats\n",
        "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
        "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
        "\n",
        "        # Compute edge embeddings\n",
        "        u, v = g.edges()\n",
        "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
        "        return g.ndata['h'], edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_xo-3K4QRGqc"
      },
      "outputs": [],
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
        "      super(SAGE, self).__init__()\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
        "\n",
        "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
        "      if corrupt:\n",
        "        e_perm = torch.randperm(g.number_of_edges())\n",
        "        #n_perm = torch.randperm(g.number_of_nodes())\n",
        "        efeats = efeats[e_perm]\n",
        "        #nfeats = nfeats[n_perm]\n",
        "      for i, layer in enumerate(self.layers):\n",
        "        #nfeats = layer(g, nfeats, efeats)\n",
        "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
        "      #return nfeats.sum(1)\n",
        "      return nfeats.sum(1), e_feats.sum(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6uuxRtLuRJQL"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_hidden):\n",
        "      super(Discriminator, self).__init__()\n",
        "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def uniform(self, size, tensor):\n",
        "      bound = 1.0 / math.sqrt(size)\n",
        "      if tensor is not None:\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      size = self.weight.size(0)\n",
        "      self.uniform(size, self.weight)\n",
        "\n",
        "    def forward(self, features, summary):\n",
        "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
        "      return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ZPbVjlCyRUco"
      },
      "outputs": [],
      "source": [
        "class DGI(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
        "      super(DGI, self).__init__()\n",
        "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
        "      #self.discriminator = Discriminator(128)\n",
        "      self.discriminator = Discriminator(256)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "\n",
        "      positive = positive[1]\n",
        "      negative = negative[1]\n",
        "\n",
        "      summary = torch.sigmoid(positive.mean(dim=0))\n",
        "\n",
        "      positive = self.discriminator(positive, summary)\n",
        "      negative = self.discriminator(negative, summary)\n",
        "\n",
        "      l1 = self.loss(positive, torch.ones_like(positive))\n",
        "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
        "\n",
        "      return l1 + l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sKnfpWFMR19u"
      },
      "outputs": [],
      "source": [
        "ndim_in = train_g.ndata['h'].shape[1]\n",
        "hidden_features = 128\n",
        "ndim_out = 128\n",
        "num_layers = 1\n",
        "edim = train_g.edata['h'].shape[1]\n",
        "learning_rate = 1e-3\n",
        "epochs = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "aSl_9qY8SbA0"
      },
      "outputs": [],
      "source": [
        "dgi = DGI(ndim_in,\n",
        "    ndim_out,\n",
        "    edim,\n",
        "    F.relu)\n",
        "\n",
        "dgi = dgi.to(device)\n",
        "\n",
        "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
        "                lr=1e-3,\n",
        "                weight_decay=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9K6_cOiWSdJA"
      },
      "outputs": [],
      "source": [
        "# Format node and edge features for E-GraphSAGE\n",
        "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
        "                                   (train_g.ndata['h'].shape[0], 1,\n",
        "                                    train_g.ndata['h'].shape[1]))\n",
        "\n",
        "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
        "                                   (train_g.edata['h'].shape[0], 1,\n",
        "                                    train_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "O44auIyWSexg"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "train_g = train_g.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gZtafIdxSheN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00000 | Time(s) nan | Loss 1.4016 | ETputs(KTEPS) nan\n",
            "Epoch 00050 | Time(s) 0.2011 | Loss 1.3670 | ETputs(KTEPS) 3350.63\n",
            "Epoch 00100 | Time(s) 0.2022 | Loss 1.1483 | ETputs(KTEPS) 3333.44\n",
            "Epoch 00150 | Time(s) 0.2026 | Loss 0.2514 | ETputs(KTEPS) 3326.89\n",
            "Epoch 00200 | Time(s) 0.2024 | Loss 0.0968 | ETputs(KTEPS) 3329.12\n",
            "Epoch 00250 | Time(s) 0.2023 | Loss 0.0770 | ETputs(KTEPS) 3332.10\n",
            "Epoch 00300 | Time(s) 0.2021 | Loss 0.0652 | ETputs(KTEPS) 3335.03\n",
            "Epoch 00350 | Time(s) 0.2019 | Loss 0.0584 | ETputs(KTEPS) 3337.47\n",
            "Epoch 00400 | Time(s) 0.2019 | Loss 0.0538 | ETputs(KTEPS) 3338.83\n",
            "Epoch 00450 | Time(s) 0.2017 | Loss 0.0485 | ETputs(KTEPS) 3340.62\n",
            "Epoch 00500 | Time(s) 0.2016 | Loss 0.0437 | ETputs(KTEPS) 3342.89\n",
            "Epoch 00550 | Time(s) 0.2015 | Loss 0.0401 | ETputs(KTEPS) 3344.86\n",
            "Epoch 00600 | Time(s) 0.2014 | Loss 0.0362 | ETputs(KTEPS) 3346.54\n",
            "Epoch 00650 | Time(s) 0.2013 | Loss 0.0323 | ETputs(KTEPS) 3347.44\n",
            "Epoch 00700 | Time(s) 0.2012 | Loss 0.0286 | ETputs(KTEPS) 3348.86\n",
            "Epoch 00750 | Time(s) 0.2012 | Loss 6.2142 | ETputs(KTEPS) 3349.48\n",
            "Epoch 00800 | Time(s) 0.2012 | Loss 1.3955 | ETputs(KTEPS) 3350.45\n",
            "Epoch 00850 | Time(s) 0.2011 | Loss 1.3619 | ETputs(KTEPS) 3351.33\n",
            "Epoch 00900 | Time(s) 0.2010 | Loss 1.3119 | ETputs(KTEPS) 3352.50\n",
            "Epoch 00950 | Time(s) 0.2010 | Loss 0.8244 | ETputs(KTEPS) 3352.37\n",
            "Epoch 01000 | Time(s) 0.2010 | Loss 0.2271 | ETputs(KTEPS) 3352.22\n",
            "Epoch 01050 | Time(s) 0.2010 | Loss 0.1667 | ETputs(KTEPS) 3352.70\n",
            "Epoch 01100 | Time(s) 0.2010 | Loss 0.1483 | ETputs(KTEPS) 3352.96\n",
            "Epoch 01150 | Time(s) 0.2010 | Loss 0.1360 | ETputs(KTEPS) 3353.13\n",
            "Epoch 01200 | Time(s) 0.2010 | Loss 0.1265 | ETputs(KTEPS) 3353.63\n",
            "Epoch 01250 | Time(s) 0.2009 | Loss 0.1137 | ETputs(KTEPS) 3353.88\n",
            "Epoch 01300 | Time(s) 0.2009 | Loss 0.0987 | ETputs(KTEPS) 3354.07\n",
            "Epoch 01350 | Time(s) 0.2009 | Loss 0.0927 | ETputs(KTEPS) 3354.48\n",
            "Epoch 01400 | Time(s) 0.2009 | Loss 0.0846 | ETputs(KTEPS) 3355.04\n",
            "Epoch 01450 | Time(s) 0.2009 | Loss 0.0773 | ETputs(KTEPS) 3355.05\n",
            "Epoch 01500 | Time(s) 0.2009 | Loss 0.0691 | ETputs(KTEPS) 3355.34\n",
            "Epoch 01550 | Time(s) 0.2008 | Loss 0.0649 | ETputs(KTEPS) 3355.87\n",
            "Epoch 01600 | Time(s) 0.2008 | Loss 0.0921 | ETputs(KTEPS) 3356.18\n",
            "Epoch 01650 | Time(s) 0.2008 | Loss 0.0577 | ETputs(KTEPS) 3356.06\n",
            "Epoch 01700 | Time(s) 0.2008 | Loss 0.0562 | ETputs(KTEPS) 3356.27\n",
            "Epoch 01750 | Time(s) 0.2008 | Loss 0.0521 | ETputs(KTEPS) 3356.50\n",
            "Epoch 01800 | Time(s) 0.2008 | Loss 0.0490 | ETputs(KTEPS) 3356.61\n",
            "Epoch 01850 | Time(s) 0.2008 | Loss 0.0429 | ETputs(KTEPS) 3355.96\n",
            "Epoch 01900 | Time(s) 0.2009 | Loss 0.0395 | ETputs(KTEPS) 3355.43\n",
            "Epoch 01950 | Time(s) 0.2009 | Loss 0.0357 | ETputs(KTEPS) 3354.91\n",
            "Epoch 02000 | Time(s) 0.2009 | Loss 0.0349 | ETputs(KTEPS) 3354.37\n",
            "Epoch 02050 | Time(s) 0.2009 | Loss 0.0326 | ETputs(KTEPS) 3353.85\n",
            "Epoch 02100 | Time(s) 0.2010 | Loss 0.0318 | ETputs(KTEPS) 3353.23\n",
            "Epoch 02150 | Time(s) 0.2010 | Loss 0.0288 | ETputs(KTEPS) 3352.78\n",
            "Epoch 02200 | Time(s) 0.2010 | Loss 0.0259 | ETputs(KTEPS) 3352.38\n",
            "Epoch 02250 | Time(s) 0.2011 | Loss 0.0249 | ETputs(KTEPS) 3351.94\n",
            "Epoch 02300 | Time(s) 0.2011 | Loss 0.0238 | ETputs(KTEPS) 3351.47\n",
            "Epoch 02350 | Time(s) 0.2011 | Loss 0.0226 | ETputs(KTEPS) 3351.03\n",
            "Epoch 02400 | Time(s) 0.2011 | Loss 0.0218 | ETputs(KTEPS) 3350.64\n",
            "Epoch 02450 | Time(s) 0.2011 | Loss 0.0189 | ETputs(KTEPS) 3350.71\n",
            "Epoch 02500 | Time(s) 0.2011 | Loss 0.0193 | ETputs(KTEPS) 3350.73\n",
            "Epoch 02550 | Time(s) 0.2011 | Loss 0.0189 | ETputs(KTEPS) 3350.79\n",
            "Epoch 02600 | Time(s) 0.2011 | Loss 0.0166 | ETputs(KTEPS) 3351.17\n",
            "Epoch 02650 | Time(s) 0.2011 | Loss 0.0167 | ETputs(KTEPS) 3351.56\n",
            "Epoch 02700 | Time(s) 0.2011 | Loss 0.0151 | ETputs(KTEPS) 3351.96\n",
            "Epoch 02750 | Time(s) 0.2010 | Loss 0.0144 | ETputs(KTEPS) 3352.31\n",
            "Epoch 02800 | Time(s) 0.2010 | Loss 0.0138 | ETputs(KTEPS) 3352.66\n",
            "Epoch 02850 | Time(s) 0.2010 | Loss 0.0140 | ETputs(KTEPS) 3353.01\n",
            "Epoch 02900 | Time(s) 0.2010 | Loss 0.0128 | ETputs(KTEPS) 3353.32\n",
            "Epoch 02950 | Time(s) 0.2010 | Loss 0.0119 | ETputs(KTEPS) 3353.63\n",
            "Epoch 03000 | Time(s) 0.2009 | Loss 0.0120 | ETputs(KTEPS) 3353.94\n",
            "Epoch 03050 | Time(s) 0.2009 | Loss 0.0126 | ETputs(KTEPS) 3354.22\n",
            "Epoch 03100 | Time(s) 0.2009 | Loss 0.0121 | ETputs(KTEPS) 3354.53\n",
            "Epoch 03150 | Time(s) 0.2009 | Loss 0.0120 | ETputs(KTEPS) 3354.80\n",
            "Epoch 03200 | Time(s) 0.2009 | Loss 0.0108 | ETputs(KTEPS) 3355.06\n",
            "Epoch 03250 | Time(s) 0.2009 | Loss 0.0108 | ETputs(KTEPS) 3355.33\n",
            "Epoch 03300 | Time(s) 0.2008 | Loss 0.0102 | ETputs(KTEPS) 3355.57\n",
            "Epoch 03350 | Time(s) 0.2008 | Loss 0.0105 | ETputs(KTEPS) 3355.83\n",
            "Epoch 03400 | Time(s) 0.2008 | Loss 0.0094 | ETputs(KTEPS) 3356.05\n",
            "Epoch 03450 | Time(s) 0.2008 | Loss 0.0096 | ETputs(KTEPS) 3356.29\n",
            "Epoch 03500 | Time(s) 0.2008 | Loss 0.0101 | ETputs(KTEPS) 3356.50\n",
            "Epoch 03550 | Time(s) 0.2008 | Loss 0.0097 | ETputs(KTEPS) 3356.71\n",
            "Epoch 03600 | Time(s) 0.2008 | Loss 0.0098 | ETputs(KTEPS) 3356.94\n",
            "Epoch 03650 | Time(s) 0.2008 | Loss 0.0094 | ETputs(KTEPS) 3357.15\n",
            "Epoch 03700 | Time(s) 0.2007 | Loss 0.0093 | ETputs(KTEPS) 3357.33\n",
            "Epoch 03750 | Time(s) 0.2007 | Loss 0.0087 | ETputs(KTEPS) 3357.54\n",
            "Epoch 03800 | Time(s) 0.2007 | Loss 0.0092 | ETputs(KTEPS) 3357.73\n",
            "Epoch 03850 | Time(s) 0.2007 | Loss 0.0086 | ETputs(KTEPS) 3357.91\n",
            "Epoch 03900 | Time(s) 0.2007 | Loss 0.0086 | ETputs(KTEPS) 3358.08\n",
            "Epoch 03950 | Time(s) 0.2007 | Loss 0.0081 | ETputs(KTEPS) 3358.27\n"
          ]
        }
      ],
      "source": [
        "cnt_wait = 0\n",
        "best = 1e9\n",
        "best_t = 0\n",
        "dur = []\n",
        "node_features = train_g.ndata['h']\n",
        "edge_features = train_g.edata['h']\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    dgi.train()\n",
        "    if epoch >= 3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    dgi_optimizer.zero_grad()\n",
        "    loss = dgi(train_g, node_features, edge_features)\n",
        "    loss.backward()\n",
        "    dgi_optimizer.step()\n",
        "\n",
        "    if loss < best:\n",
        "        best = loss\n",
        "        best_t = epoch\n",
        "        cnt_wait = 0\n",
        "        torch.save(dgi.state_dict(), 'best_dgi.pkl')\n",
        "    else:\n",
        "        cnt_wait += 1\n",
        "\n",
        "  # if cnt_wait == patience:\n",
        "  #     print('Early stopping!')\n",
        "  #     break\n",
        "\n",
        "    if epoch >= 3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "\n",
        "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
        "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
        "              loss.item(),\n",
        "              train_g.num_edges() / np.mean(dur) / 1000))\n",
        "# ... existing code ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RZ2HAQDAF-4c",
        "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_26930/597080661.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dgi.load_state_dict(torch.load('best_dgi.pkl'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dgi.load_state_dict(torch.load('best_dgi.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6Ek16GkRStKP"
      },
      "outputs": [],
      "source": [
        "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
        "training_emb = training_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-FwaBlOdS4ep"
      },
      "outputs": [],
      "source": [
        "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
        "                                   (test_g.ndata['h'].shape[0], 1,\n",
        "                                    test_g.ndata['h'].shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
        "                                   (test_g.edata['h'].shape[0], 1,\n",
        "                                    test_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "SBa-rdivS6cQ"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "test_g = test_g.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "W12WLjslS-kx"
      },
      "outputs": [],
      "source": [
        "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
        "testing_emb = testing_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "ERsOAMjeS_D8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(training_emb, )\n",
        "df_train[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        train_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
        "\n",
        "df_test = pd.DataFrame(testing_emb, )\n",
        "df_test[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        test_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "B8p79H9dat5T",
        "outputId": "0d6e82d8-5d02-49eb-a16f-d44e52ea3dff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.003993</td>\n",
              "      <td>0.029602</td>\n",
              "      <td>-0.073997</td>\n",
              "      <td>-0.035304</td>\n",
              "      <td>-0.057061</td>\n",
              "      <td>-0.031729</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>0.048595</td>\n",
              "      <td>0.051252</td>\n",
              "      <td>-0.003702</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003208</td>\n",
              "      <td>0.003734</td>\n",
              "      <td>-0.027365</td>\n",
              "      <td>-0.000895</td>\n",
              "      <td>0.046468</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.013361</td>\n",
              "      <td>0.010224</td>\n",
              "      <td>DDOS attack-HOIC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003993</td>\n",
              "      <td>0.029602</td>\n",
              "      <td>-0.073997</td>\n",
              "      <td>-0.035304</td>\n",
              "      <td>-0.057061</td>\n",
              "      <td>-0.031729</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>0.048595</td>\n",
              "      <td>0.051252</td>\n",
              "      <td>-0.003702</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003208</td>\n",
              "      <td>0.003734</td>\n",
              "      <td>-0.027365</td>\n",
              "      <td>-0.000895</td>\n",
              "      <td>0.046468</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.013361</td>\n",
              "      <td>0.010224</td>\n",
              "      <td>DDOS attack-HOIC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.003993</td>\n",
              "      <td>0.029602</td>\n",
              "      <td>-0.073997</td>\n",
              "      <td>-0.035304</td>\n",
              "      <td>-0.057061</td>\n",
              "      <td>-0.031729</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>0.048595</td>\n",
              "      <td>0.051252</td>\n",
              "      <td>-0.003702</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003208</td>\n",
              "      <td>0.003734</td>\n",
              "      <td>-0.027365</td>\n",
              "      <td>-0.000895</td>\n",
              "      <td>0.046468</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.013361</td>\n",
              "      <td>0.010224</td>\n",
              "      <td>DDOS attack-HOIC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.003993</td>\n",
              "      <td>0.029602</td>\n",
              "      <td>-0.073997</td>\n",
              "      <td>-0.035304</td>\n",
              "      <td>-0.057061</td>\n",
              "      <td>-0.031729</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>0.048595</td>\n",
              "      <td>0.051252</td>\n",
              "      <td>-0.003702</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003208</td>\n",
              "      <td>0.003734</td>\n",
              "      <td>-0.027365</td>\n",
              "      <td>-0.000895</td>\n",
              "      <td>0.046468</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.013361</td>\n",
              "      <td>0.010224</td>\n",
              "      <td>DDOS attack-HOIC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.003993</td>\n",
              "      <td>0.029602</td>\n",
              "      <td>-0.073997</td>\n",
              "      <td>-0.035304</td>\n",
              "      <td>-0.057061</td>\n",
              "      <td>-0.031729</td>\n",
              "      <td>-0.075933</td>\n",
              "      <td>0.048595</td>\n",
              "      <td>0.051252</td>\n",
              "      <td>-0.003702</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.003208</td>\n",
              "      <td>0.003734</td>\n",
              "      <td>-0.027365</td>\n",
              "      <td>-0.000895</td>\n",
              "      <td>0.046468</td>\n",
              "      <td>0.000642</td>\n",
              "      <td>0.013361</td>\n",
              "      <td>0.010224</td>\n",
              "      <td>DDOS attack-HOIC</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673945</th>\n",
              "      <td>0.025786</td>\n",
              "      <td>0.059814</td>\n",
              "      <td>-0.022930</td>\n",
              "      <td>0.037751</td>\n",
              "      <td>-0.032899</td>\n",
              "      <td>0.004213</td>\n",
              "      <td>-0.069948</td>\n",
              "      <td>-0.010040</td>\n",
              "      <td>0.006247</td>\n",
              "      <td>-0.019991</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003293</td>\n",
              "      <td>0.040431</td>\n",
              "      <td>0.012497</td>\n",
              "      <td>0.029120</td>\n",
              "      <td>0.026577</td>\n",
              "      <td>-0.009339</td>\n",
              "      <td>0.033992</td>\n",
              "      <td>-0.011904</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673946</th>\n",
              "      <td>0.012710</td>\n",
              "      <td>0.050273</td>\n",
              "      <td>-0.021694</td>\n",
              "      <td>0.040512</td>\n",
              "      <td>-0.040932</td>\n",
              "      <td>-0.005700</td>\n",
              "      <td>-0.066764</td>\n",
              "      <td>-0.005599</td>\n",
              "      <td>0.012955</td>\n",
              "      <td>-0.011116</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.002057</td>\n",
              "      <td>0.045031</td>\n",
              "      <td>0.002866</td>\n",
              "      <td>0.021179</td>\n",
              "      <td>0.023044</td>\n",
              "      <td>-0.005885</td>\n",
              "      <td>0.039423</td>\n",
              "      <td>-0.016999</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673947</th>\n",
              "      <td>0.021983</td>\n",
              "      <td>0.056845</td>\n",
              "      <td>-0.023819</td>\n",
              "      <td>0.037691</td>\n",
              "      <td>-0.037772</td>\n",
              "      <td>0.001478</td>\n",
              "      <td>-0.070110</td>\n",
              "      <td>-0.010086</td>\n",
              "      <td>0.008569</td>\n",
              "      <td>-0.017335</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>0.041813</td>\n",
              "      <td>0.010638</td>\n",
              "      <td>0.026475</td>\n",
              "      <td>0.025749</td>\n",
              "      <td>-0.009338</td>\n",
              "      <td>0.037241</td>\n",
              "      <td>-0.014834</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673948</th>\n",
              "      <td>0.009540</td>\n",
              "      <td>0.052301</td>\n",
              "      <td>-0.016863</td>\n",
              "      <td>0.038848</td>\n",
              "      <td>-0.042323</td>\n",
              "      <td>-0.003629</td>\n",
              "      <td>-0.067921</td>\n",
              "      <td>-0.011576</td>\n",
              "      <td>0.013820</td>\n",
              "      <td>-0.012596</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002484</td>\n",
              "      <td>0.043894</td>\n",
              "      <td>0.002460</td>\n",
              "      <td>0.020876</td>\n",
              "      <td>0.022586</td>\n",
              "      <td>-0.006100</td>\n",
              "      <td>0.045977</td>\n",
              "      <td>-0.014441</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>673949</th>\n",
              "      <td>0.019372</td>\n",
              "      <td>0.054824</td>\n",
              "      <td>-0.033505</td>\n",
              "      <td>0.030281</td>\n",
              "      <td>-0.061917</td>\n",
              "      <td>0.002605</td>\n",
              "      <td>-0.079575</td>\n",
              "      <td>-0.025051</td>\n",
              "      <td>0.013183</td>\n",
              "      <td>-0.016299</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.011899</td>\n",
              "      <td>0.042238</td>\n",
              "      <td>0.018766</td>\n",
              "      <td>0.023005</td>\n",
              "      <td>0.028020</td>\n",
              "      <td>-0.017513</td>\n",
              "      <td>0.056269</td>\n",
              "      <td>-0.027230</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>673950 rows Ã— 258 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0         1         2         3         4         5         6  \\\n",
              "0       0.003993  0.029602 -0.073997 -0.035304 -0.057061 -0.031729 -0.075933   \n",
              "1       0.003993  0.029602 -0.073997 -0.035304 -0.057061 -0.031729 -0.075933   \n",
              "2       0.003993  0.029602 -0.073997 -0.035304 -0.057061 -0.031729 -0.075933   \n",
              "3       0.003993  0.029602 -0.073997 -0.035304 -0.057061 -0.031729 -0.075933   \n",
              "4       0.003993  0.029602 -0.073997 -0.035304 -0.057061 -0.031729 -0.075933   \n",
              "...          ...       ...       ...       ...       ...       ...       ...   \n",
              "673945  0.025786  0.059814 -0.022930  0.037751 -0.032899  0.004213 -0.069948   \n",
              "673946  0.012710  0.050273 -0.021694  0.040512 -0.040932 -0.005700 -0.066764   \n",
              "673947  0.021983  0.056845 -0.023819  0.037691 -0.037772  0.001478 -0.070110   \n",
              "673948  0.009540  0.052301 -0.016863  0.038848 -0.042323 -0.003629 -0.067921   \n",
              "673949  0.019372  0.054824 -0.033505  0.030281 -0.061917  0.002605 -0.079575   \n",
              "\n",
              "               7         8         9  ...       248       249       250  \\\n",
              "0       0.048595  0.051252 -0.003702  ... -0.003208  0.003734 -0.027365   \n",
              "1       0.048595  0.051252 -0.003702  ... -0.003208  0.003734 -0.027365   \n",
              "2       0.048595  0.051252 -0.003702  ... -0.003208  0.003734 -0.027365   \n",
              "3       0.048595  0.051252 -0.003702  ... -0.003208  0.003734 -0.027365   \n",
              "4       0.048595  0.051252 -0.003702  ... -0.003208  0.003734 -0.027365   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "673945 -0.010040  0.006247 -0.019991  ...  0.003293  0.040431  0.012497   \n",
              "673946 -0.005599  0.012955 -0.011116  ... -0.002057  0.045031  0.002866   \n",
              "673947 -0.010086  0.008569 -0.017335  ...  0.000178  0.041813  0.010638   \n",
              "673948 -0.011576  0.013820 -0.012596  ...  0.002484  0.043894  0.002460   \n",
              "673949 -0.025051  0.013183 -0.016299  ... -0.011899  0.042238  0.018766   \n",
              "\n",
              "             251       252       253       254       255            Attack  \\\n",
              "0      -0.000895  0.046468  0.000642  0.013361  0.010224  DDOS attack-HOIC   \n",
              "1      -0.000895  0.046468  0.000642  0.013361  0.010224  DDOS attack-HOIC   \n",
              "2      -0.000895  0.046468  0.000642  0.013361  0.010224  DDOS attack-HOIC   \n",
              "3      -0.000895  0.046468  0.000642  0.013361  0.010224  DDOS attack-HOIC   \n",
              "4      -0.000895  0.046468  0.000642  0.013361  0.010224  DDOS attack-HOIC   \n",
              "...          ...       ...       ...       ...       ...               ...   \n",
              "673945  0.029120  0.026577 -0.009339  0.033992 -0.011904            Benign   \n",
              "673946  0.021179  0.023044 -0.005885  0.039423 -0.016999            Benign   \n",
              "673947  0.026475  0.025749 -0.009338  0.037241 -0.014834            Benign   \n",
              "673948  0.020876  0.022586 -0.006100  0.045977 -0.014441            Benign   \n",
              "673949  0.023005  0.028020 -0.017513  0.056269 -0.027230            Benign   \n",
              "\n",
              "        Label  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  \n",
              "...       ...  \n",
              "673945      0  \n",
              "673946      0  \n",
              "673947      0  \n",
              "673948      0  \n",
              "673949      0  \n",
              "\n",
              "[673950 rows x 258 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ScEk1y_TzzX"
      },
      "source": [
        "# Embeddings CBLOF  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZYABKzdrTGas"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "RkFS_-dcTJeK"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "62BUDLtO4mla"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyod in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (2.0.4)\n",
            "Requirement already satisfied: joblib in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (3.7.5)\n",
            "Requirement already satisfied: numpy>=1.19 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.24.1)\n",
            "Requirement already satisfied: numba>=0.51 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.3.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from numba>=0.51->pyod) (0.41.1)\n",
            "Requirement already satisfied: importlib-metadata in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from numba>=0.51->pyod) (8.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from scikit-learn>=0.22.0->pyod) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (6.4.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->pyod) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->pyod) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pyod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "2i48uLj74mla",
        "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  3%|â–Ž         | 1/36 [00:46<27:17, 46.79s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  6%|â–Œ         | 2/36 [01:32<26:18, 46.42s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  8%|â–Š         | 3/36 [02:17<24:57, 45.38s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 11%|â–ˆ         | 4/36 [03:01<23:57, 44.91s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 14%|â–ˆâ–        | 5/36 [03:48<23:35, 45.67s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 17%|â–ˆâ–‹        | 6/36 [04:33<22:45, 45.50s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 19%|â–ˆâ–‰        | 7/36 [05:40<25:23, 52.53s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 22%|â–ˆâ–ˆâ–       | 8/36 [06:45<26:21, 56.50s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 9/36 [07:48<26:22, 58.60s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 28%|â–ˆâ–ˆâ–Š       | 10/36 [09:00<27:06, 62.55s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [10:04<26:18, 63.13s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 12/36 [11:10<25:35, 63.96s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [12:30<26:23, 68.84s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [13:49<26:25, 72.06s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [15:09<26:02, 74.39s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [16:30<25:27, 76.37s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [17:49<24:23, 77.01s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [19:08<23:17, 77.61s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 19/36 [20:45<23:39, 83.50s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [22:38<24:40, 92.50s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [24:29<24:29, 97.94s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [26:20<23:45, 101.85s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [28:03<22:10, 102.31s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [29:47<20:33, 102.83s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [31:59<20:27, 111.58s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [34:09<19:29, 116.94s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [36:19<18:07, 120.81s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [38:27<16:24, 123.11s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [40:38<14:37, 125.43s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 30/36 [42:47<12:39, 126.56s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [45:27<11:22, 136.46s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [47:56<09:21, 140.39s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [50:27<07:10, 143.44s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [53:04<04:55, 147.60s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [55:43<02:30, 150.87s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [58:24<00:00, 97.35s/it] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 8, 'con': 0.01}\n",
            "0.9220114987248272\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9541    0.9842    0.9689    227729\n",
            "           1     0.9334    0.8236    0.8751     61106\n",
            "\n",
            "    accuracy                         0.9503    288835\n",
            "   macro avg     0.9438    0.9039    0.9220    288835\n",
            "weighted avg     0.9497    0.9503    0.9491    288835\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyod.models.cblof import CBLOF\n",
        "n_est = [8, 12, 15, 20, 25, 30]  # Try larger cluster counts\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    # Add alpha and beta parameters with more relaxed values\n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con, alpha=0.7, beta=3)\n",
        "    try:\n",
        "        clf_if.fit(benign_train_samples)\n",
        "        y_pred = clf_if.predict(test_samples)\n",
        "        test_pred = y_pred\n",
        "\n",
        "        f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "        if f1 > score:\n",
        "            score = f1\n",
        "            best_params = {'n_estimators': n_est,\n",
        "                          \"con\": con\n",
        "                }\n",
        "            bs = test_pred\n",
        "    except Exception as e:\n",
        "        print(f\"Error with n_clusters={n_est}, contamination={con}: {str(e)}\")\n",
        "        continue\n",
        "    \n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "rK-Rng9q4mla",
        "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  3%|â–Ž         | 1/36 [00:18<10:35, 18.14s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  3%|â–Ž         | 1/36 [00:30<17:33, 30.11s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[42], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_est, con \u001b[38;5;129;01min\u001b[39;00m tqdm(params):\n\u001b[1;32m      8\u001b[0m     clf_if \u001b[38;5;241m=\u001b[39m CBLOF(n_clusters\u001b[38;5;241m=\u001b[39mn_est, contamination\u001b[38;5;241m=\u001b[39mcon)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mclf_if\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_train_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf_if\u001b[38;5;241m.\u001b[39mpredict(test_samples)\n\u001b[1;32m     11\u001b[0m     test_pred \u001b[38;5;241m=\u001b[39m y_pred\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/pyod/models/cblof.py:177\u001b[0m, in \u001b[0;36mCBLOF.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# check parameters\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# number of clusters are default to 8\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_estimator(default\u001b[38;5;241m=\u001b[39mKMeans(\n\u001b[1;32m    174\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters,\n\u001b[1;32m    175\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state))\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclustering_estimator_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# Get the labels of the clustering results\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# labels_ is consistent across sklearn clustering algorithms\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_labels_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclustering_estimator_\u001b[38;5;241m.\u001b[39mlabels_\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1519\u001b[0m, in \u001b[0;36mKMeans.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1515\u001b[0m best_inertia, best_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_init):\n\u001b[1;32m   1518\u001b[0m     \u001b[38;5;66;03m# Initialize centers\u001b[39;00m\n\u001b[0;32m-> 1519\u001b[0m     centers_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_centroids\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m   1527\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitialization complete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1019\u001b[0m, in \u001b[0;36m_BaseKMeans._init_centroids\u001b[0;34m(self, X, x_squared_norms, init, random_state, sample_weight, init_size, n_centroids)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight[init_indices]\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-means++\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1019\u001b[0m     centers, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_kmeans_plusplus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1020\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1021\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx_squared_norms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(init, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m init \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1027\u001b[0m     seeds \u001b[38;5;241m=\u001b[39m random_state\u001b[38;5;241m.\u001b[39mchoice(\n\u001b[1;32m   1028\u001b[0m         n_samples,\n\u001b[1;32m   1029\u001b[0m         size\u001b[38;5;241m=\u001b[39mn_clusters,\n\u001b[1;32m   1030\u001b[0m         replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1031\u001b[0m         p\u001b[38;5;241m=\u001b[39msample_weight \u001b[38;5;241m/\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum(),\n\u001b[1;32m   1032\u001b[0m     )\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:238\u001b[0m, in \u001b[0;36m_kmeans_plusplus\u001b[0;34m(X, n_clusters, x_squared_norms, sample_weight, random_state, n_local_trials)\u001b[0m\n\u001b[1;32m    235\u001b[0m indices[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m center_id\n\u001b[1;32m    237\u001b[0m \u001b[38;5;66;03m# Initialize list of closest distances and calculate current potential\u001b[39;00m\n\u001b[0;32m--> 238\u001b[0m closest_dist_sq \u001b[38;5;241m=\u001b[39m \u001b[43m_euclidean_distances\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_norm_squared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_squared_norms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msquared\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    240\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m current_pot \u001b[38;5;241m=\u001b[39m closest_dist_sq \u001b[38;5;241m@\u001b[39m sample_weight\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# Pick the remaining n_clusters-1 points\u001b[39;00m\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:376\u001b[0m, in \u001b[0;36m_euclidean_distances\u001b[0;34m(X, Y, X_norm_squared, Y_norm_squared, squared)\u001b[0m\n\u001b[1;32m    371\u001b[0m         YY \u001b[38;5;241m=\u001b[39m row_norms(Y, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[np\u001b[38;5;241m.\u001b[39mnewaxis, :]\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# To minimize precision issues with float32, we compute the distance\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;66;03m# matrix on chunks of X and Y upcast to float64\u001b[39;00m\n\u001b[0;32m--> 376\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43m_euclidean_distances_upcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mXX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;66;03m# if dtype is already float64, no need to chunk and upcast\u001b[39;00m\n\u001b[1;32m    379\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m safe_sparse_dot(X, Y\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/metrics/pairwise.py:588\u001b[0m, in \u001b[0;36m_euclidean_distances_upcast\u001b[0;34m(X, XX, Y, YY, batch_size)\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m     YY_chunk \u001b[38;5;241m=\u001b[39m YY[:, y_slice]\n\u001b[0;32m--> 588\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msafe_sparse_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_chunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdense_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m d \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m XX_chunk\n\u001b[1;32m    590\u001b[0m d \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m YY_chunk\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/utils/extmath.py:192\u001b[0m, in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    190\u001b[0m         ret \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(a, b)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    195\u001b[0m     sparse\u001b[38;5;241m.\u001b[39missparse(a)\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(b)\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dense_output\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoarray\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    199\u001b[0m ):\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39mtoarray()\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHSOcEhH4mlb"
      },
      "outputs": [],
      "source": [
        "###  CBLOF RAW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A--j-9Cu4mlb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-D3nCuXX4mlb"
      },
      "outputs": [],
      "source": [
        "df_raw_train = pd.concat([X_train.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_train], axis=1)\n",
        "df_raw_test = pd.concat([X_test.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "8Zr57GFE4mlb"
      },
      "outputs": [],
      "source": [
        "raw_benign_train_samples = df_raw_train[df_raw_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "raw_normal_train_samples = df_raw_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "raw_train_labels = df_raw_train[\"Label\"]\n",
        "raw_test_labels = df_raw_test[\"Label\"]\n",
        "\n",
        "raw_test_samples = df_raw_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "u_l1Vz8S4mlb",
        "outputId": "c1b8d03c-7105-42d9-f49a-bba4ff4905a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|â–ˆâ–‰        | 7/36 [00:01<00:05,  5.27it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 22%|â–ˆâ–ˆâ–       | 8/36 [00:01<00:05,  5.10it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 25%|â–ˆâ–ˆâ–Œ       | 9/36 [00:01<00:05,  5.02it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 28%|â–ˆâ–ˆâ–Š       | 10/36 [00:01<00:05,  4.95it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 31%|â–ˆâ–ˆâ–ˆ       | 11/36 [00:02<00:05,  4.88it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 12/36 [00:02<00:04,  4.85it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 13/36 [00:02<00:04,  4.80it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 39%|â–ˆâ–ˆâ–ˆâ–‰      | 14/36 [00:02<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 15/36 [00:03<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 16/36 [00:03<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 17/36 [00:03<00:03,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 18/36 [00:03<00:03,  4.79it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 19/36 [00:03<00:03,  4.74it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 20/36 [00:04<00:03,  4.69it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 21/36 [00:04<00:03,  4.65it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 22/36 [00:04<00:03,  4.60it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 23/36 [00:04<00:02,  4.36it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 24/36 [00:05<00:02,  4.40it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 25/36 [00:05<00:02,  4.45it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/36 [00:05<00:02,  4.46it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 27/36 [00:05<00:02,  4.48it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 28/36 [00:05<00:01,  4.42it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 29/36 [00:06<00:01,  4.41it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 30/36 [00:06<00:01,  4.47it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 31/36 [00:06<00:01,  4.45it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 32/36 [00:06<00:00,  4.43it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/36 [00:07<00:00,  4.43it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 34/36 [00:07<00:00,  4.44it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 35/36 [00:07<00:00,  4.40it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [00:07<00:00,  4.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.2}\n",
            "0.3971858513564739\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0294    0.7949    0.0566        39\n",
            "           1     0.9945    0.5864    0.7378      2478\n",
            "\n",
            "    accuracy                         0.5896      2517\n",
            "   macro avg     0.5119    0.6906    0.3972      2517\n",
            "weighted avg     0.9796    0.5896    0.7272      2517\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-_InJ1-4mlc",
        "outputId": "e22139e6-d1cf-46e1-adf3-f0dc9b499244"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [20:42<00:00, 34.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 2}\n",
            "0.8618432811826696\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9591    0.9806    0.9697    499068\n",
            "           1     0.8287    0.6916    0.7540     67744\n",
            "\n",
            "    accuracy                         0.9461    566812\n",
            "   macro avg     0.8939    0.8361    0.8618    566812\n",
            "weighted avg     0.9435    0.9461    0.9439    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GneWZNtq4mlc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd0-H7UT4mlc"
      },
      "outputs": [],
      "source": [
        "# HBOS  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a34ZbzAX4mld"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDquxErU4mld"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG5Hcs9r4mld"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLBIT-Rc4mld",
        "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [19:29<00:00, 32.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.01}\n",
            "0.945069359337394\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9845    0.9897    0.9871    996643\n",
            "           1     0.9213    0.8855    0.9030    135488\n",
            "\n",
            "    accuracy                         0.9772   1132131\n",
            "   macro avg     0.9529    0.9376    0.9451   1132131\n",
            "weighted avg     0.9769    0.9772    0.9770   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.hbos import HBOS\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDcX0mma4mld",
        "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [21:10<00:00, 35.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.1}\n",
            "0.9189314026948445\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9705    0.9945    0.9824    996643\n",
            "           1     0.9503    0.7779    0.8555    135488\n",
            "\n",
            "    accuracy                         0.9686   1132131\n",
            "   macro avg     0.9604    0.8862    0.9189   1132131\n",
            "weighted avg     0.9681    0.9686    0.9672   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRUOrQqB4mle"
      },
      "outputs": [],
      "source": [
        "##  HBOS  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sZfAnER4mle",
        "outputId": "6e9cb145-8540-4aa7-8ed1-fc9aca495b07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:09<00:00,  3.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 30, 'con': 0.04}\n",
            "0.8627757960209628\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9715    0.9601    0.9658    499068\n",
            "           1     0.7294    0.7928    0.7598     67744\n",
            "\n",
            "    accuracy                         0.9401    566812\n",
            "   macro avg     0.8505    0.8765    0.8628    566812\n",
            "weighted avg     0.9426    0.9401    0.9412    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5A-gLN34mle",
        "outputId": "8a6dfd26-a45b-4ce3-8d85-1b61652e7f90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [02:14<00:00,  3.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 5}\n",
            "0.7882018992795334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9766    0.8943    0.9337    499068\n",
            "           1     0.5197    0.8422    0.6427     67744\n",
            "\n",
            "    accuracy                         0.8881    566812\n",
            "   macro avg     0.7481    0.8683    0.7882    566812\n",
            "weighted avg     0.9220    0.8881    0.8989    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0ZCfgyi4mle"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbDOqrcy4mle"
      },
      "outputs": [],
      "source": [
        "##  PCA  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDCu7S6i4mle"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nga82Fw_4mle",
        "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [29:47<00:00, 49.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.001}\n",
            "0.9442956641768174\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9770    0.9988    0.9878    996643\n",
            "           1     0.9896    0.8267    0.9008    135488\n",
            "\n",
            "    accuracy                         0.9782   1132131\n",
            "   macro avg     0.9833    0.9127    0.9443   1132131\n",
            "weighted avg     0.9785    0.9782    0.9774   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.pca import PCA\n",
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg6AcAUW4mlf",
        "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [32:26<00:00, 54.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.1}\n",
            "0.9256946497974641\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9723    0.9955    0.9838    996643\n",
            "           1     0.9598    0.7916    0.8676    135488\n",
            "\n",
            "    accuracy                         0.9711   1132131\n",
            "   macro avg     0.9661    0.8935    0.9257   1132131\n",
            "weighted avg     0.9708    0.9711    0.9699   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSoyZpDu4mlf"
      },
      "outputs": [],
      "source": [
        "##  PCA  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hKgicW14mlf",
        "outputId": "16c93b66-4eac-4d40-d5ce-96f3b3a5b3bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [07:28<00:00, 12.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.1}\n",
            "0.7684270275042566\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9639    0.9009    0.9313    499068\n",
            "           1     0.5071    0.7513    0.6055     67744\n",
            "\n",
            "    accuracy                         0.8830    566812\n",
            "   macro avg     0.7355    0.8261    0.7684    566812\n",
            "weighted avg     0.9093    0.8830    0.8924    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples)\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAdfwnlP4mlf",
        "outputId": "ddc9c2b4-a3b6-4ab6-cc74-7ed93ca23d22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 36/36 [08:04<00:00, 13.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 10}\n",
            "0.7376147683157477\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9622    0.8744    0.9162    499068\n",
            "           1     0.4466    0.7471    0.5590     67744\n",
            "\n",
            "    accuracy                         0.8591    566812\n",
            "   macro avg     0.7044    0.8107    0.7376    566812\n",
            "weighted avg     0.9006    0.8591    0.8735    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples)\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdfI45oD4mlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSNV8IRT4mlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi8SO3tL4mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D0m4vb04mlg",
        "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [3:09:47<00:00, 474.46s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.001}\n",
            "0.9538863735449246\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9805    0.9992    0.9897    996643\n",
            "           1     0.9928    0.8538    0.9180    135488\n",
            "\n",
            "    accuracy                         0.9818   1132131\n",
            "   macro avg     0.9866    0.9265    0.9539   1132131\n",
            "weighted avg     0.9820    0.9818    0.9812   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCj-3u4t4mlg",
        "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [3:31:56<00:00, 529.86s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 50, 'con': 0.2}\n",
            "0.8110535459623227\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9878    0.8952    0.9392    996643\n",
            "           1     0.5436    0.9184    0.6829    135488\n",
            "\n",
            "    accuracy                         0.8979   1132131\n",
            "   macro avg     0.7657    0.9068    0.8111   1132131\n",
            "weighted avg     0.9346    0.8979    0.9085   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOIn_Kr44mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_60yAo34mlg",
        "outputId": "354e56cd-ee22-4538-ba6f-43c1d67eb648"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [19:12<00:00, 48.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.05}\n",
            "0.8176793439704795\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9599    0.9494    0.9547    499068\n",
            "           1     0.6553    0.7082    0.6807     67744\n",
            "\n",
            "    accuracy                         0.9206    566812\n",
            "   macro avg     0.8076    0.8288    0.8177    566812\n",
            "weighted avg     0.9235    0.9206    0.9219    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples.to_numpy())\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xNKBA7X4mlh",
        "outputId": "cd0ee1c5-5394-4e2b-efde-1f58bf922282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 24/24 [20:38<00:00, 51.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 100}\n",
            "0.7409370706714709\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9633    0.8755    0.9173    499068\n",
            "           1     0.4512    0.7539    0.5646     67744\n",
            "\n",
            "    accuracy                         0.8610    566812\n",
            "   macro avg     0.7072    0.8147    0.7409    566812\n",
            "weighted avg     0.9021    0.8610    0.8751    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples.to_numpy())\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYBqJ8y14mlh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gnn_cuda_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
