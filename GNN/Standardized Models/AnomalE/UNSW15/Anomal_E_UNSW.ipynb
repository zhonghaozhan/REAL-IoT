{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hjc3iIihKLn-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from dgl.data import DGLDataset\n",
        "import dgl\n",
        "import time\n",
        "import networkx as nx\n",
        "import category_encoders as ce\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "from typing import *\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "import socket\n",
        "import struct\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SvWHb_BpKsLq"
      },
      "outputs": [],
      "source": [
        "file_name = \"/media/ssd/test/standardized-datasets/netflow/nf_unsw_nb15_standardized.csv\"\n",
        "data = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "fqly1y-LMwYS",
        "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "0    2295222\n",
              "1      95053\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3t4OREvSM33h"
      },
      "outputs": [],
      "source": [
        "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
        "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
        "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
        "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bTtHq0XqNXxI"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNIP-8zNkn9",
        "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Benign', 'Exploits', 'Generic', 'Fuzzers', 'Backdoor', 'DoS',\n",
              "       'Reconnaissance', 'Shellcode', 'Worms', 'Analysis'], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Attack.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AlPa58fVN7gB"
      },
      "outputs": [],
      "source": [
        "data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "lcfAP6ViOp-J",
        "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>Label</th>\n",
              "      <th>flow_id</th>\n",
              "      <th>dataset_source</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attack</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "      <td>230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Backdoor</th>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>...</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "      <td>217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>...</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "      <td>229522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS</th>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>...</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Exploits</th>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>...</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "      <td>3155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Fuzzers</th>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>...</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "      <td>2231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Generic</th>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>...</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "      <td>1656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reconnaissance</th>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>...</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "      <td>1278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Shellcode</th>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>...</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "      <td>143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Worms</th>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  \\\n",
              "Attack                                                                       \n",
              "Analysis                  230            230       230       230       230   \n",
              "Backdoor                  217            217       217       217       217   \n",
              "Benign                 229522         229522    229522    229522    229522   \n",
              "DoS                       579            579       579       579       579   \n",
              "Exploits                 3155           3155      3155      3155      3155   \n",
              "Fuzzers                  2231           2231      2231      2231      2231   \n",
              "Generic                  1656           1656      1656      1656      1656   \n",
              "Reconnaissance           1278           1278      1278      1278      1278   \n",
              "Shellcode                 143            143       143       143       143   \n",
              "Worms                      16             16        16        16        16   \n",
              "\n",
              "                IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  \\\n",
              "Attack                                                                      \n",
              "Analysis            230        230       230        230               230   \n",
              "Backdoor            217        217       217        217               217   \n",
              "Benign           229522     229522    229522     229522            229522   \n",
              "DoS                 579        579       579        579               579   \n",
              "Exploits           3155       3155      3155       3155              3155   \n",
              "Fuzzers            2231       2231      2231       2231              2231   \n",
              "Generic            1656       1656      1656       1656              1656   \n",
              "Reconnaissance     1278       1278      1278       1278              1278   \n",
              "Shellcode           143        143       143        143               143   \n",
              "Worms                16         16        16         16                16   \n",
              "\n",
              "                ...  TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  \\\n",
              "Attack          ...                                                             \n",
              "Analysis        ...              230        230             230           230   \n",
              "Backdoor        ...              217        217             217           217   \n",
              "Benign          ...           229522     229522          229522        229522   \n",
              "DoS             ...              579        579             579           579   \n",
              "Exploits        ...             3155       3155            3155          3155   \n",
              "Fuzzers         ...             2231       2231            2231          2231   \n",
              "Generic         ...             1656       1656            1656          1656   \n",
              "Reconnaissance  ...             1278       1278            1278          1278   \n",
              "Shellcode       ...              143        143             143           143   \n",
              "Worms           ...               16         16              16            16   \n",
              "\n",
              "                DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE   Label  \\\n",
              "Attack                                                                         \n",
              "Analysis                   230             230                   230     230   \n",
              "Backdoor                   217             217                   217     217   \n",
              "Benign                  229522          229522                229522  229522   \n",
              "DoS                        579             579                   579     579   \n",
              "Exploits                  3155            3155                  3155    3155   \n",
              "Fuzzers                   2231            2231                  2231    2231   \n",
              "Generic                   1656            1656                  1656    1656   \n",
              "Reconnaissance            1278            1278                  1278    1278   \n",
              "Shellcode                  143             143                   143     143   \n",
              "Worms                       16              16                    16      16   \n",
              "\n",
              "                flow_id  dataset_source  \n",
              "Attack                                   \n",
              "Analysis            230             230  \n",
              "Backdoor            217             217  \n",
              "Benign           229522          229522  \n",
              "DoS                 579             579  \n",
              "Exploits           3155            3155  \n",
              "Fuzzers            2231            2231  \n",
              "Generic            1656            1656  \n",
              "Reconnaissance     1278            1278  \n",
              "Shellcode           143             143  \n",
              "Worms                16              16  \n",
              "\n",
              "[10 rows x 44 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.groupby(by=\"Attack\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FqRx5xCPOuv8"
      },
      "outputs": [],
      "source": [
        "X = data.drop(columns=[\"Attack\", \"Label\"])\n",
        "y = data[[\"Attack\", \"Label\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=13, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bPfakXplPGGx"
      },
      "outputs": [],
      "source": [
        "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
        "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
        "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
        "                                  'FTP_COMMAND_RET_CODE'])\n",
        "encoder.fit(X_train, y_train.Label)\n",
        "\n",
        "# Transform on training set\n",
        "X_train = encoder.transform(X_train)\n",
        "\n",
        "# Transform on testing set\n",
        "X_test = encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ibyOfV-8PouK"
      },
      "outputs": [],
      "source": [
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'dataset_source' in X_train.columns:\n",
        "    X_train = X_train.drop(columns=['dataset_source'])\n",
        "if 'dataset_source' in X_test.columns:\n",
        "    X_test = X_test.drop(columns=['dataset_source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "asDnsSIWPee0"
      },
      "outputs": [],
      "source": [
        "scaler = Normalizer()\n",
        "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
        "scaler.fit(X_train[cols_to_norm])\n",
        "\n",
        "# Transform on training set\n",
        "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
        "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
        "\n",
        "# Transform on testing set\n",
        "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
        "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
        "\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "test = pd.concat([X_test, y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "hErQbsnrPluV",
        "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>flow_id</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>220614</th>\n",
              "      <td>59.166.0.4</td>\n",
              "      <td>149.171.126.1</td>\n",
              "      <td>4.799343e-09</td>\n",
              "      <td>3.046911e-09</td>\n",
              "      <td>3.992291e-05</td>\n",
              "      <td>7.648066e-07</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>1.070729e-06</td>\n",
              "      <td>1.979102e-09</td>\n",
              "      <td>1.979232e-09</td>\n",
              "      <td>...</td>\n",
              "      <td>1.328928e-03</td>\n",
              "      <td>1.328928e-03</td>\n",
              "      <td>4.041250e-10</td>\n",
              "      <td>4.041250e-10</td>\n",
              "      <td>6.310571e-09</td>\n",
              "      <td>6.310616e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.616402e-09</td>\n",
              "      <td>0.033745</td>\n",
              "      <td>[4.79934325210543e-09, 3.046911229391236e-09, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329844</th>\n",
              "      <td>59.166.0.1</td>\n",
              "      <td>149.171.126.8</td>\n",
              "      <td>9.004294e-09</td>\n",
              "      <td>8.034034e-09</td>\n",
              "      <td>1.076602e-04</td>\n",
              "      <td>8.281552e-07</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>8.281552e-07</td>\n",
              "      <td>1.393801e-08</td>\n",
              "      <td>1.393694e-08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>1.179036e-08</td>\n",
              "      <td>1.179838e-08</td>\n",
              "      <td>8.541591e-09</td>\n",
              "      <td>8.541651e-09</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.249878e-09</td>\n",
              "      <td>0.068291</td>\n",
              "      <td>[9.004293599058882e-09, 8.0340336076954e-09, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1093665</th>\n",
              "      <td>59.166.0.3</td>\n",
              "      <td>149.171.126.8</td>\n",
              "      <td>3.068685e-13</td>\n",
              "      <td>8.437668e-13</td>\n",
              "      <td>1.638983e-07</td>\n",
              "      <td>3.061234e-09</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>7.129838e-09</td>\n",
              "      <td>1.188386e-13</td>\n",
              "      <td>1.274923e-13</td>\n",
              "      <td>...</td>\n",
              "      <td>6.372843e-07</td>\n",
              "      <td>7.080936e-08</td>\n",
              "      <td>4.545956e-14</td>\n",
              "      <td>5.191930e-14</td>\n",
              "      <td>4.034959e-13</td>\n",
              "      <td>4.034988e-13</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.369547e-13</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>[3.068684887458359e-13, 8.437667728375511e-13,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1764268</th>\n",
              "      <td>59.166.0.4</td>\n",
              "      <td>149.171.126.0</td>\n",
              "      <td>1.705243e-08</td>\n",
              "      <td>1.521494e-08</td>\n",
              "      <td>5.724548e-05</td>\n",
              "      <td>7.841846e-07</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>7.841846e-07</td>\n",
              "      <td>2.639595e-08</td>\n",
              "      <td>2.639392e-08</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>2.232872e-08</td>\n",
              "      <td>2.234389e-08</td>\n",
              "      <td>1.356214e-08</td>\n",
              "      <td>2.583379e-10</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>1.751752e-08</td>\n",
              "      <td>0.691756</td>\n",
              "      <td>[1.7052427913141602e-08, 1.5214939122076362e-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1525176</th>\n",
              "      <td>59.166.0.9</td>\n",
              "      <td>149.171.126.5</td>\n",
              "      <td>2.309217e-10</td>\n",
              "      <td>2.855922e-10</td>\n",
              "      <td>1.717771e-05</td>\n",
              "      <td>2.649519e-07</td>\n",
              "      <td>0.000124</td>\n",
              "      <td>2.796714e-07</td>\n",
              "      <td>8.942727e-11</td>\n",
              "      <td>9.593926e-11</td>\n",
              "      <td>...</td>\n",
              "      <td>1.598543e-04</td>\n",
              "      <td>1.065695e-04</td>\n",
              "      <td>5.174558e-12</td>\n",
              "      <td>5.174558e-12</td>\n",
              "      <td>3.036348e-10</td>\n",
              "      <td>3.036369e-10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.288128e-10</td>\n",
              "      <td>0.011225</td>\n",
              "      <td>[2.3092165458478978e-10, 2.855922428474074e-10...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        IPV4_SRC_ADDR  IPV4_DST_ADDR      PROTOCOL      L7_PROTO  \\\n",
              "220614     59.166.0.4  149.171.126.1  4.799343e-09  3.046911e-09   \n",
              "329844     59.166.0.1  149.171.126.8  9.004294e-09  8.034034e-09   \n",
              "1093665    59.166.0.3  149.171.126.8  3.068685e-13  8.437668e-13   \n",
              "1764268    59.166.0.4  149.171.126.0  1.705243e-08  1.521494e-08   \n",
              "1525176    59.166.0.9  149.171.126.5  2.309217e-10  2.855922e-10   \n",
              "\n",
              "             IN_BYTES       IN_PKTS  OUT_BYTES      OUT_PKTS     TCP_FLAGS  \\\n",
              "220614   3.992291e-05  7.648066e-07   0.000072  1.070729e-06  1.979102e-09   \n",
              "329844   1.076602e-04  8.281552e-07   0.000063  8.281552e-07  1.393801e-08   \n",
              "1093665  1.638983e-07  3.061234e-09   0.000010  7.129838e-09  1.188386e-13   \n",
              "1764268  5.724548e-05  7.841846e-07   0.000070  7.841846e-07  2.639595e-08   \n",
              "1525176  1.717771e-05  2.649519e-07   0.000124  2.796714e-07  8.942727e-11   \n",
              "\n",
              "         CLIENT_TCP_FLAGS  ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  \\\n",
              "220614       1.979232e-09  ...    1.328928e-03     1.328928e-03  4.041250e-10   \n",
              "329844       1.393694e-08  ...    0.000000e+00     0.000000e+00  1.179036e-08   \n",
              "1093665      1.274923e-13  ...    6.372843e-07     7.080936e-08  4.545956e-14   \n",
              "1764268      2.639392e-08  ...    0.000000e+00     0.000000e+00  2.232872e-08   \n",
              "1525176      9.593926e-11  ...    1.598543e-04     1.065695e-04  5.174558e-12   \n",
              "\n",
              "         ICMP_IPV4_TYPE  DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  \\\n",
              "220614     4.041250e-10  6.310571e-09    6.310616e-09        0.000000   \n",
              "329844     1.179838e-08  8.541591e-09    8.541651e-09        0.000000   \n",
              "1093665    5.191930e-14  4.034959e-13    4.034988e-13        0.000000   \n",
              "1764268    2.234389e-08  1.356214e-08    2.583379e-10        0.000024   \n",
              "1525176    5.174558e-12  3.036348e-10    3.036369e-10        0.000000   \n",
              "\n",
              "         FTP_COMMAND_RET_CODE   flow_id  \\\n",
              "220614           3.616402e-09  0.033745   \n",
              "329844           9.249878e-09  0.068291   \n",
              "1093665          4.369547e-13  0.000011   \n",
              "1764268          1.751752e-08  0.691756   \n",
              "1525176          3.288128e-10  0.011225   \n",
              "\n",
              "                                                         h  \n",
              "220614   [4.79934325210543e-09, 3.046911229391236e-09, ...  \n",
              "329844   [9.004293599058882e-09, 8.0340336076954e-09, 0...  \n",
              "1093665  [3.068684887458359e-13, 8.437667728375511e-13,...  \n",
              "1764268  [1.7052427913141602e-08, 1.5214939122076362e-0...  \n",
              "1525176  [2.3092165458478978e-10, 2.855922428474074e-10...  \n",
              "\n",
              "[5 rows x 43 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "d_tLtK4WPtrF"
      },
      "outputs": [],
      "source": [
        "lab_enc = preprocessing.LabelEncoder()\n",
        "lab_enc.fit(data[\"Attack\"])\n",
        "\n",
        "# Transform on training set\n",
        "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
        "\n",
        "# Transform on testing set\n",
        "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8yaicjecP1fZ"
      },
      "outputs": [],
      "source": [
        "# Training graph\n",
        "\n",
        "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "train_g = train_g.to_directed()\n",
        "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
        "train_g.edata['h'].shape[1]])\n",
        "train_g.ndata['h'] = nfeat_weight\n",
        "\n",
        "# Testing graph\n",
        "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "test_g = test_g.to_directed()\n",
        "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
        "test_g.edata['h'].shape[1]])\n",
        "test_g.ndata['h'] = nfeat_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PUV6DgJ9QRaP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import tqdm\n",
        "import gc\n",
        "\n",
        "class SAGELayer(nn.Module):\n",
        "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
        "      super(SAGELayer, self).__init__()\n",
        "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
        "      self.activation = F.relu\n",
        "      self.W_edge = nn.Linear(128 * 2, 256)\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      gain = nn.init.calculate_gain('relu')\n",
        "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
        "\n",
        "    def message_func(self, edges):\n",
        "      return {'m':  edges.data['h']}\n",
        "\n",
        "    def forward(self, g_dgl, nfeats, efeats):\n",
        "      with g_dgl.local_scope():\n",
        "        g = g_dgl\n",
        "        g.ndata['h'] = nfeats\n",
        "        g.edata['h'] = efeats\n",
        "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
        "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
        "\n",
        "        # Compute edge embeddings\n",
        "        u, v = g.edges()\n",
        "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
        "        return g.ndata['h'], edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_xo-3K4QRGqc"
      },
      "outputs": [],
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
        "      super(SAGE, self).__init__()\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
        "\n",
        "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
        "      if corrupt:\n",
        "        e_perm = torch.randperm(g.number_of_edges())\n",
        "        #n_perm = torch.randperm(g.number_of_nodes())\n",
        "        efeats = efeats[e_perm]\n",
        "        #nfeats = nfeats[n_perm]\n",
        "      for i, layer in enumerate(self.layers):\n",
        "        #nfeats = layer(g, nfeats, efeats)\n",
        "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
        "      #return nfeats.sum(1)\n",
        "      return nfeats.sum(1), e_feats.sum(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6uuxRtLuRJQL"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_hidden):\n",
        "      super(Discriminator, self).__init__()\n",
        "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def uniform(self, size, tensor):\n",
        "      bound = 1.0 / math.sqrt(size)\n",
        "      if tensor is not None:\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      size = self.weight.size(0)\n",
        "      self.uniform(size, self.weight)\n",
        "\n",
        "    def forward(self, features, summary):\n",
        "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
        "      return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZPbVjlCyRUco"
      },
      "outputs": [],
      "source": [
        "class DGI(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
        "      super(DGI, self).__init__()\n",
        "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
        "      #self.discriminator = Discriminator(128)\n",
        "      self.discriminator = Discriminator(256)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "\n",
        "      positive = positive[1]\n",
        "      negative = negative[1]\n",
        "\n",
        "      summary = torch.sigmoid(positive.mean(dim=0))\n",
        "\n",
        "      positive = self.discriminator(positive, summary)\n",
        "      negative = self.discriminator(negative, summary)\n",
        "\n",
        "      l1 = self.loss(positive, torch.ones_like(positive))\n",
        "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
        "\n",
        "      return l1 + l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sKnfpWFMR19u"
      },
      "outputs": [],
      "source": [
        "ndim_in = train_g.ndata['h'].shape[1]\n",
        "hidden_features = 128\n",
        "ndim_out = 128\n",
        "num_layers = 1\n",
        "edim = train_g.edata['h'].shape[1]\n",
        "learning_rate = 1e-3\n",
        "epochs = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aSl_9qY8SbA0"
      },
      "outputs": [],
      "source": [
        "dgi = DGI(ndim_in,\n",
        "    ndim_out,\n",
        "    edim,\n",
        "    F.relu)\n",
        "\n",
        "dgi = dgi.to(device)\n",
        "\n",
        "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
        "                lr=1e-3,\n",
        "                weight_decay=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9K6_cOiWSdJA"
      },
      "outputs": [],
      "source": [
        "# Format node and edge features for E-GraphSAGE\n",
        "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
        "                                   (train_g.ndata['h'].shape[0], 1,\n",
        "                                    train_g.ndata['h'].shape[1]))\n",
        "\n",
        "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
        "                                   (train_g.edata['h'].shape[0], 1,\n",
        "                                    train_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "O44auIyWSexg"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "train_g = train_g.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gZtafIdxSheN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00000 | Time(s) nan | Loss 1.9820 | ETputs(KTEPS) nan\n",
            "Epoch 00050 | Time(s) 0.0790 | Loss 1.4002 | ETputs(KTEPS) 4237.33\n",
            "Epoch 00100 | Time(s) 0.0794 | Loss 1.3846 | ETputs(KTEPS) 4214.57\n",
            "Epoch 00150 | Time(s) 0.0800 | Loss 1.3821 | ETputs(KTEPS) 4184.01\n",
            "Epoch 00200 | Time(s) 0.0800 | Loss 1.3789 | ETputs(KTEPS) 4181.20\n",
            "Epoch 00250 | Time(s) 0.0801 | Loss 1.3649 | ETputs(KTEPS) 4179.90\n",
            "Epoch 00300 | Time(s) 0.0801 | Loss 1.3529 | ETputs(KTEPS) 4178.61\n",
            "Epoch 00350 | Time(s) 0.0800 | Loss 1.3231 | ETputs(KTEPS) 4180.89\n",
            "Epoch 00400 | Time(s) 0.0800 | Loss 1.2865 | ETputs(KTEPS) 4183.42\n",
            "Epoch 00450 | Time(s) 0.0800 | Loss 1.2024 | ETputs(KTEPS) 4182.78\n",
            "Epoch 00500 | Time(s) 0.0800 | Loss 1.0599 | ETputs(KTEPS) 4185.48\n",
            "Epoch 00550 | Time(s) 0.0798 | Loss 1.3756 | ETputs(KTEPS) 4191.48\n",
            "Epoch 00600 | Time(s) 0.0797 | Loss 0.9476 | ETputs(KTEPS) 4199.84\n",
            "Epoch 00650 | Time(s) 0.0796 | Loss 0.7150 | ETputs(KTEPS) 4203.58\n",
            "Epoch 00700 | Time(s) 0.0795 | Loss 0.6629 | ETputs(KTEPS) 4207.29\n",
            "Epoch 00750 | Time(s) 0.0795 | Loss 0.6626 | ETputs(KTEPS) 4209.05\n",
            "Epoch 00800 | Time(s) 0.0795 | Loss 0.4119 | ETputs(KTEPS) 4206.67\n",
            "Epoch 00850 | Time(s) 0.0796 | Loss 0.1441 | ETputs(KTEPS) 4205.01\n",
            "Epoch 00900 | Time(s) 0.0796 | Loss 0.0936 | ETputs(KTEPS) 4202.27\n",
            "Epoch 00950 | Time(s) 0.0797 | Loss 0.0626 | ETputs(KTEPS) 4198.33\n",
            "Epoch 01000 | Time(s) 0.0797 | Loss 0.0499 | ETputs(KTEPS) 4197.79\n",
            "Epoch 01050 | Time(s) 0.0797 | Loss 0.0392 | ETputs(KTEPS) 4197.31\n",
            "Epoch 01100 | Time(s) 0.0797 | Loss 0.0359 | ETputs(KTEPS) 4197.19\n",
            "Epoch 01150 | Time(s) 0.0797 | Loss 0.0219 | ETputs(KTEPS) 4197.30\n",
            "Epoch 01200 | Time(s) 0.0797 | Loss 0.0219 | ETputs(KTEPS) 4198.02\n",
            "Epoch 01250 | Time(s) 0.0797 | Loss 0.0199 | ETputs(KTEPS) 4198.26\n",
            "Epoch 01300 | Time(s) 0.0797 | Loss 0.0182 | ETputs(KTEPS) 4198.90\n",
            "Epoch 01350 | Time(s) 0.0797 | Loss 0.0128 | ETputs(KTEPS) 4199.30\n",
            "Epoch 01400 | Time(s) 0.0797 | Loss 0.0112 | ETputs(KTEPS) 4199.77\n",
            "Epoch 01450 | Time(s) 0.0797 | Loss 0.0096 | ETputs(KTEPS) 4200.40\n",
            "Epoch 01500 | Time(s) 0.0797 | Loss 0.0139 | ETputs(KTEPS) 4201.03\n",
            "Epoch 01550 | Time(s) 0.0796 | Loss 0.0119 | ETputs(KTEPS) 4201.44\n",
            "Epoch 01600 | Time(s) 0.0796 | Loss 0.0087 | ETputs(KTEPS) 4201.59\n",
            "Epoch 01650 | Time(s) 0.0796 | Loss 0.0083 | ETputs(KTEPS) 4201.93\n",
            "Epoch 01700 | Time(s) 0.0796 | Loss 1.3261 | ETputs(KTEPS) 4201.90\n",
            "Epoch 01750 | Time(s) 0.0796 | Loss 1.2112 | ETputs(KTEPS) 4204.10\n",
            "Epoch 01800 | Time(s) 0.0796 | Loss 1.0305 | ETputs(KTEPS) 4205.84\n",
            "Epoch 01850 | Time(s) 0.0795 | Loss 0.7035 | ETputs(KTEPS) 4208.20\n",
            "Epoch 01900 | Time(s) 0.0795 | Loss 0.6607 | ETputs(KTEPS) 4210.56\n",
            "Epoch 01950 | Time(s) 0.0794 | Loss 0.3672 | ETputs(KTEPS) 4212.87\n",
            "Epoch 02000 | Time(s) 0.0794 | Loss 0.2567 | ETputs(KTEPS) 4215.15\n",
            "Epoch 02050 | Time(s) 0.0794 | Loss 0.1649 | ETputs(KTEPS) 4216.14\n",
            "Epoch 02100 | Time(s) 0.0794 | Loss 0.1027 | ETputs(KTEPS) 4216.80\n",
            "Epoch 02150 | Time(s) 0.0793 | Loss 0.0683 | ETputs(KTEPS) 4218.00\n",
            "Epoch 02200 | Time(s) 0.0793 | Loss 0.0526 | ETputs(KTEPS) 4219.45\n",
            "Epoch 02250 | Time(s) 0.0793 | Loss 0.0470 | ETputs(KTEPS) 4221.23\n",
            "Epoch 02300 | Time(s) 0.0792 | Loss 0.0350 | ETputs(KTEPS) 4222.88\n",
            "Epoch 02350 | Time(s) 0.0792 | Loss 0.0305 | ETputs(KTEPS) 4223.88\n",
            "Epoch 02400 | Time(s) 0.0792 | Loss 0.0255 | ETputs(KTEPS) 4224.43\n",
            "Epoch 02450 | Time(s) 0.0792 | Loss 0.0180 | ETputs(KTEPS) 4225.09\n",
            "Epoch 02500 | Time(s) 0.0792 | Loss 0.0176 | ETputs(KTEPS) 4225.92\n",
            "Epoch 02550 | Time(s) 0.0792 | Loss 0.0207 | ETputs(KTEPS) 4226.96\n",
            "Epoch 02600 | Time(s) 0.0792 | Loss 0.0243 | ETputs(KTEPS) 4227.81\n",
            "Epoch 02650 | Time(s) 0.0791 | Loss 0.0124 | ETputs(KTEPS) 4228.07\n",
            "Epoch 02700 | Time(s) 0.0791 | Loss 0.0169 | ETputs(KTEPS) 4228.08\n",
            "Epoch 02750 | Time(s) 0.0791 | Loss 0.0100 | ETputs(KTEPS) 4228.78\n",
            "Epoch 02800 | Time(s) 0.0791 | Loss 0.0165 | ETputs(KTEPS) 4230.32\n",
            "Epoch 02850 | Time(s) 0.0791 | Loss 0.0071 | ETputs(KTEPS) 4231.97\n",
            "Epoch 02900 | Time(s) 0.0790 | Loss 0.0086 | ETputs(KTEPS) 4233.52\n",
            "Epoch 02950 | Time(s) 0.0790 | Loss 0.0068 | ETputs(KTEPS) 4235.08\n",
            "Epoch 03000 | Time(s) 0.0790 | Loss 0.0058 | ETputs(KTEPS) 4236.41\n",
            "Epoch 03050 | Time(s) 0.0790 | Loss 0.0135 | ETputs(KTEPS) 4237.08\n",
            "Epoch 03100 | Time(s) 0.0790 | Loss 0.0120 | ETputs(KTEPS) 4238.14\n",
            "Epoch 03150 | Time(s) 0.0789 | Loss 0.0088 | ETputs(KTEPS) 4239.08\n",
            "Epoch 03200 | Time(s) 0.0789 | Loss 0.0053 | ETputs(KTEPS) 4240.02\n",
            "Epoch 03250 | Time(s) 0.0789 | Loss 0.0055 | ETputs(KTEPS) 4240.92\n",
            "Epoch 03300 | Time(s) 0.0789 | Loss 0.0074 | ETputs(KTEPS) 4241.31\n",
            "Epoch 03350 | Time(s) 0.0789 | Loss 0.0061 | ETputs(KTEPS) 4241.83\n",
            "Epoch 03400 | Time(s) 0.0789 | Loss 0.0093 | ETputs(KTEPS) 4241.86\n",
            "Epoch 03450 | Time(s) 0.0789 | Loss 1.2959 | ETputs(KTEPS) 4241.98\n",
            "Epoch 03500 | Time(s) 0.0789 | Loss 1.2476 | ETputs(KTEPS) 4243.17\n",
            "Epoch 03550 | Time(s) 0.0788 | Loss 1.1033 | ETputs(KTEPS) 4244.29\n",
            "Epoch 03600 | Time(s) 0.0788 | Loss 0.9703 | ETputs(KTEPS) 4245.35\n",
            "Epoch 03650 | Time(s) 0.0788 | Loss 0.8375 | ETputs(KTEPS) 4246.43\n",
            "Epoch 03700 | Time(s) 0.0788 | Loss 0.7787 | ETputs(KTEPS) 4247.40\n",
            "Epoch 03750 | Time(s) 0.0788 | Loss 0.4994 | ETputs(KTEPS) 4248.27\n",
            "Epoch 03800 | Time(s) 0.0788 | Loss 0.5348 | ETputs(KTEPS) 4249.14\n",
            "Epoch 03850 | Time(s) 0.0787 | Loss 0.2616 | ETputs(KTEPS) 4250.05\n",
            "Epoch 03900 | Time(s) 0.0787 | Loss 0.1991 | ETputs(KTEPS) 4250.89\n",
            "Epoch 03950 | Time(s) 0.0787 | Loss 0.2346 | ETputs(KTEPS) 4251.73\n"
          ]
        }
      ],
      "source": [
        "cnt_wait = 0\n",
        "best = 1e9\n",
        "best_t = 0\n",
        "dur = []\n",
        "node_features = train_g.ndata['h']\n",
        "edge_features = train_g.edata['h']\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    dgi.train()\n",
        "    if epoch >= 3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    dgi_optimizer.zero_grad()\n",
        "    loss = dgi(train_g, node_features, edge_features)\n",
        "    loss.backward()\n",
        "    dgi_optimizer.step()\n",
        "\n",
        "    if loss < best:\n",
        "        best = loss\n",
        "        best_t = epoch\n",
        "        cnt_wait = 0\n",
        "        torch.save(dgi.state_dict(), 'best_dgi.pkl')\n",
        "    else:\n",
        "        cnt_wait += 1\n",
        "\n",
        "  # if cnt_wait == patience:\n",
        "  #     print('Early stopping!')\n",
        "  #     break\n",
        "\n",
        "    if epoch >= 3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "\n",
        "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
        "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
        "              loss.item(),\n",
        "              train_g.num_edges() / np.mean(dur) / 1000))\n",
        "# ... existing code ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RZ2HAQDAF-4c",
        "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_4188052/597080661.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dgi.load_state_dict(torch.load('best_dgi.pkl'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dgi.load_state_dict(torch.load('best_dgi.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6Ek16GkRStKP"
      },
      "outputs": [],
      "source": [
        "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
        "training_emb = training_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-FwaBlOdS4ep"
      },
      "outputs": [],
      "source": [
        "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
        "                                   (test_g.ndata['h'].shape[0], 1,\n",
        "                                    test_g.ndata['h'].shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
        "                                   (test_g.edata['h'].shape[0], 1,\n",
        "                                    test_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SBa-rdivS6cQ"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "test_g = test_g.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "W12WLjslS-kx"
      },
      "outputs": [],
      "source": [
        "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
        "testing_emb = testing_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ERsOAMjeS_D8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(training_emb, )\n",
        "df_train[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        train_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
        "\n",
        "df_test = pd.DataFrame(testing_emb, )\n",
        "df_test[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        test_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "B8p79H9dat5T",
        "outputId": "0d6e82d8-5d02-49eb-a16f-d44e52ea3dff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.028651</td>\n",
              "      <td>0.01135</td>\n",
              "      <td>-0.016843</td>\n",
              "      <td>-0.010814</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>0.018754</td>\n",
              "      <td>0.016268</td>\n",
              "      <td>0.005725</td>\n",
              "      <td>-0.009464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041502</td>\n",
              "      <td>-0.021986</td>\n",
              "      <td>-0.010696</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>0.043754</td>\n",
              "      <td>-0.017725</td>\n",
              "      <td>-0.032184</td>\n",
              "      <td>0.001297</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.028651</td>\n",
              "      <td>0.01135</td>\n",
              "      <td>-0.016843</td>\n",
              "      <td>-0.010814</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>0.018754</td>\n",
              "      <td>0.016268</td>\n",
              "      <td>0.005725</td>\n",
              "      <td>-0.009464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041502</td>\n",
              "      <td>-0.021986</td>\n",
              "      <td>-0.010696</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>0.043754</td>\n",
              "      <td>-0.017725</td>\n",
              "      <td>-0.032184</td>\n",
              "      <td>0.001297</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.028651</td>\n",
              "      <td>0.01135</td>\n",
              "      <td>-0.016843</td>\n",
              "      <td>-0.010814</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>0.018754</td>\n",
              "      <td>0.016268</td>\n",
              "      <td>0.005725</td>\n",
              "      <td>-0.009464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041502</td>\n",
              "      <td>-0.021986</td>\n",
              "      <td>-0.010696</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>0.043754</td>\n",
              "      <td>-0.017725</td>\n",
              "      <td>-0.032184</td>\n",
              "      <td>0.001297</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.028651</td>\n",
              "      <td>0.01135</td>\n",
              "      <td>-0.016843</td>\n",
              "      <td>-0.010814</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>0.018754</td>\n",
              "      <td>0.016268</td>\n",
              "      <td>0.005725</td>\n",
              "      <td>-0.009464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041502</td>\n",
              "      <td>-0.021986</td>\n",
              "      <td>-0.010696</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>0.043754</td>\n",
              "      <td>-0.017725</td>\n",
              "      <td>-0.032184</td>\n",
              "      <td>0.001297</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.028651</td>\n",
              "      <td>0.01135</td>\n",
              "      <td>-0.016843</td>\n",
              "      <td>-0.010814</td>\n",
              "      <td>0.003143</td>\n",
              "      <td>0.003494</td>\n",
              "      <td>0.018754</td>\n",
              "      <td>0.016268</td>\n",
              "      <td>0.005725</td>\n",
              "      <td>-0.009464</td>\n",
              "      <td>...</td>\n",
              "      <td>0.041502</td>\n",
              "      <td>-0.021986</td>\n",
              "      <td>-0.010696</td>\n",
              "      <td>-0.001949</td>\n",
              "      <td>0.043754</td>\n",
              "      <td>-0.017725</td>\n",
              "      <td>-0.032184</td>\n",
              "      <td>0.001297</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334631</th>\n",
              "      <td>0.021734</td>\n",
              "      <td>0.23236</td>\n",
              "      <td>-0.001371</td>\n",
              "      <td>-0.342937</td>\n",
              "      <td>0.003244</td>\n",
              "      <td>-0.171518</td>\n",
              "      <td>-0.124611</td>\n",
              "      <td>0.002098</td>\n",
              "      <td>-0.117244</td>\n",
              "      <td>0.030774</td>\n",
              "      <td>...</td>\n",
              "      <td>0.820784</td>\n",
              "      <td>0.224955</td>\n",
              "      <td>0.137295</td>\n",
              "      <td>-0.250774</td>\n",
              "      <td>0.488516</td>\n",
              "      <td>-0.193601</td>\n",
              "      <td>-0.578108</td>\n",
              "      <td>-0.042180</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334632</th>\n",
              "      <td>0.021734</td>\n",
              "      <td>0.23236</td>\n",
              "      <td>-0.001371</td>\n",
              "      <td>-0.342937</td>\n",
              "      <td>0.003244</td>\n",
              "      <td>-0.171518</td>\n",
              "      <td>-0.124611</td>\n",
              "      <td>0.002098</td>\n",
              "      <td>-0.117244</td>\n",
              "      <td>0.030774</td>\n",
              "      <td>...</td>\n",
              "      <td>0.820784</td>\n",
              "      <td>0.224955</td>\n",
              "      <td>0.137295</td>\n",
              "      <td>-0.250774</td>\n",
              "      <td>0.488516</td>\n",
              "      <td>-0.193601</td>\n",
              "      <td>-0.578108</td>\n",
              "      <td>-0.042180</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334633</th>\n",
              "      <td>0.021734</td>\n",
              "      <td>0.23236</td>\n",
              "      <td>-0.001371</td>\n",
              "      <td>-0.342937</td>\n",
              "      <td>0.003244</td>\n",
              "      <td>-0.171518</td>\n",
              "      <td>-0.124611</td>\n",
              "      <td>0.002098</td>\n",
              "      <td>-0.117244</td>\n",
              "      <td>0.030774</td>\n",
              "      <td>...</td>\n",
              "      <td>0.820784</td>\n",
              "      <td>0.224955</td>\n",
              "      <td>0.137295</td>\n",
              "      <td>-0.250774</td>\n",
              "      <td>0.488516</td>\n",
              "      <td>-0.193601</td>\n",
              "      <td>-0.578108</td>\n",
              "      <td>-0.042180</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334634</th>\n",
              "      <td>0.021734</td>\n",
              "      <td>0.23236</td>\n",
              "      <td>-0.001371</td>\n",
              "      <td>-0.342937</td>\n",
              "      <td>0.003244</td>\n",
              "      <td>-0.171518</td>\n",
              "      <td>-0.124611</td>\n",
              "      <td>0.002098</td>\n",
              "      <td>-0.117244</td>\n",
              "      <td>0.030774</td>\n",
              "      <td>...</td>\n",
              "      <td>0.820784</td>\n",
              "      <td>0.224955</td>\n",
              "      <td>0.137295</td>\n",
              "      <td>-0.250774</td>\n",
              "      <td>0.488516</td>\n",
              "      <td>-0.193601</td>\n",
              "      <td>-0.578108</td>\n",
              "      <td>-0.042180</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334635</th>\n",
              "      <td>0.021734</td>\n",
              "      <td>0.23236</td>\n",
              "      <td>-0.001371</td>\n",
              "      <td>-0.342937</td>\n",
              "      <td>0.003244</td>\n",
              "      <td>-0.171518</td>\n",
              "      <td>-0.124611</td>\n",
              "      <td>0.002098</td>\n",
              "      <td>-0.117244</td>\n",
              "      <td>0.030774</td>\n",
              "      <td>...</td>\n",
              "      <td>0.820784</td>\n",
              "      <td>0.224955</td>\n",
              "      <td>0.137295</td>\n",
              "      <td>-0.250774</td>\n",
              "      <td>0.488516</td>\n",
              "      <td>-0.193601</td>\n",
              "      <td>-0.578108</td>\n",
              "      <td>-0.042180</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>334636 rows × 258 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               0        1         2         3         4         5         6  \\\n",
              "0       0.028651  0.01135 -0.016843 -0.010814  0.003143  0.003494  0.018754   \n",
              "1       0.028651  0.01135 -0.016843 -0.010814  0.003143  0.003494  0.018754   \n",
              "2       0.028651  0.01135 -0.016843 -0.010814  0.003143  0.003494  0.018754   \n",
              "3       0.028651  0.01135 -0.016843 -0.010814  0.003143  0.003494  0.018754   \n",
              "4       0.028651  0.01135 -0.016843 -0.010814  0.003143  0.003494  0.018754   \n",
              "...          ...      ...       ...       ...       ...       ...       ...   \n",
              "334631  0.021734  0.23236 -0.001371 -0.342937  0.003244 -0.171518 -0.124611   \n",
              "334632  0.021734  0.23236 -0.001371 -0.342937  0.003244 -0.171518 -0.124611   \n",
              "334633  0.021734  0.23236 -0.001371 -0.342937  0.003244 -0.171518 -0.124611   \n",
              "334634  0.021734  0.23236 -0.001371 -0.342937  0.003244 -0.171518 -0.124611   \n",
              "334635  0.021734  0.23236 -0.001371 -0.342937  0.003244 -0.171518 -0.124611   \n",
              "\n",
              "               7         8         9  ...       248       249       250  \\\n",
              "0       0.016268  0.005725 -0.009464  ...  0.041502 -0.021986 -0.010696   \n",
              "1       0.016268  0.005725 -0.009464  ...  0.041502 -0.021986 -0.010696   \n",
              "2       0.016268  0.005725 -0.009464  ...  0.041502 -0.021986 -0.010696   \n",
              "3       0.016268  0.005725 -0.009464  ...  0.041502 -0.021986 -0.010696   \n",
              "4       0.016268  0.005725 -0.009464  ...  0.041502 -0.021986 -0.010696   \n",
              "...          ...       ...       ...  ...       ...       ...       ...   \n",
              "334631  0.002098 -0.117244  0.030774  ...  0.820784  0.224955  0.137295   \n",
              "334632  0.002098 -0.117244  0.030774  ...  0.820784  0.224955  0.137295   \n",
              "334633  0.002098 -0.117244  0.030774  ...  0.820784  0.224955  0.137295   \n",
              "334634  0.002098 -0.117244  0.030774  ...  0.820784  0.224955  0.137295   \n",
              "334635  0.002098 -0.117244  0.030774  ...  0.820784  0.224955  0.137295   \n",
              "\n",
              "             251       252       253       254       255  Attack  Label  \n",
              "0      -0.001949  0.043754 -0.017725 -0.032184  0.001297  Benign      0  \n",
              "1      -0.001949  0.043754 -0.017725 -0.032184  0.001297  Benign      0  \n",
              "2      -0.001949  0.043754 -0.017725 -0.032184  0.001297  Benign      0  \n",
              "3      -0.001949  0.043754 -0.017725 -0.032184  0.001297  Benign      0  \n",
              "4      -0.001949  0.043754 -0.017725 -0.032184  0.001297  Benign      0  \n",
              "...          ...       ...       ...       ...       ...     ...    ...  \n",
              "334631 -0.250774  0.488516 -0.193601 -0.578108 -0.042180  Benign      0  \n",
              "334632 -0.250774  0.488516 -0.193601 -0.578108 -0.042180  Benign      0  \n",
              "334633 -0.250774  0.488516 -0.193601 -0.578108 -0.042180  Benign      0  \n",
              "334634 -0.250774  0.488516 -0.193601 -0.578108 -0.042180  Benign      0  \n",
              "334635 -0.250774  0.488516 -0.193601 -0.578108 -0.042180  Benign      0  \n",
              "\n",
              "[334636 rows x 258 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ScEk1y_TzzX"
      },
      "source": [
        "# Embeddings CBLOF  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZYABKzdrTGas"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RkFS_-dcTJeK"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "62BUDLtO4mla"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyod in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (2.0.4)\n",
            "Requirement already satisfied: joblib in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (3.7.5)\n",
            "Requirement already satisfied: numpy>=1.19 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.24.1)\n",
            "Requirement already satisfied: numba>=0.51 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.3.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from numba>=0.51->pyod) (0.41.1)\n",
            "Requirement already satisfied: importlib-metadata in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from numba>=0.51->pyod) (8.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from scikit-learn>=0.22.0->pyod) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (6.4.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->pyod) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->pyod) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pyod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2i48uLj74mla",
        "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  3%|▎         | 1/36 [00:12<07:10, 12.29s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  6%|▌         | 2/36 [00:23<06:31, 11.52s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  8%|▊         | 3/36 [00:34<06:16, 11.42s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 11%|█         | 4/36 [00:45<05:59, 11.22s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 14%|█▍        | 5/36 [00:56<05:44, 11.12s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 17%|█▋        | 6/36 [01:07<05:34, 11.14s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 19%|█▉        | 7/36 [01:22<05:54, 12.22s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 22%|██▏       | 8/36 [01:37<06:14, 13.37s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 25%|██▌       | 9/36 [01:51<06:05, 13.55s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 28%|██▊       | 10/36 [02:06<05:57, 13.76s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 31%|███       | 11/36 [02:19<05:41, 13.68s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 33%|███▎      | 12/36 [02:33<05:32, 13.86s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 36%|███▌      | 13/36 [02:52<05:55, 15.45s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 39%|███▉      | 14/36 [03:16<06:31, 17.80s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 42%|████▏     | 15/36 [03:36<06:27, 18.46s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 44%|████▍     | 16/36 [03:55<06:11, 18.58s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 47%|████▋     | 17/36 [04:13<05:54, 18.68s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 50%|█████     | 18/36 [04:32<05:37, 18.77s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 53%|█████▎    | 19/36 [05:00<06:04, 21.47s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 56%|█████▌    | 20/36 [05:27<06:07, 22.96s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 58%|█████▊    | 21/36 [05:52<05:54, 23.66s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 61%|██████    | 22/36 [06:18<05:42, 24.45s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 64%|██████▍   | 23/36 [06:42<05:15, 24.23s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 67%|██████▋   | 24/36 [07:09<04:59, 24.99s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 69%|██████▉   | 25/36 [07:41<05:00, 27.31s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 72%|███████▏  | 26/36 [08:16<04:54, 29.45s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 75%|███████▌  | 27/36 [08:51<04:39, 31.04s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 78%|███████▊  | 28/36 [09:26<04:19, 32.50s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 81%|████████  | 29/36 [10:00<03:50, 32.93s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 83%|████████▎ | 30/36 [10:33<03:16, 32.78s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 86%|████████▌ | 31/36 [11:06<02:43, 32.76s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 89%|████████▉ | 32/36 [11:42<02:14, 33.72s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 92%|█████████▏| 33/36 [12:19<01:44, 34.92s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 94%|█████████▍| 34/36 [12:54<01:09, 34.81s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 97%|█████████▋| 35/36 [13:31<00:35, 35.43s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "100%|██████████| 36/36 [14:13<00:00, 23.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 2, 'con': 0.01}\n",
            "0.8125843406399277\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9823    0.9912    0.9867    137714\n",
            "           1     0.7282    0.5684    0.6384      5704\n",
            "\n",
            "    accuracy                         0.9744    143418\n",
            "   macro avg     0.8552    0.7798    0.8126    143418\n",
            "weighted avg     0.9722    0.9744    0.9729    143418\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "n_est = [2,3,5,7,9,10]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "rK-Rng9q4mla",
        "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  3%|▎         | 1/36 [00:11<06:50, 11.74s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  6%|▌         | 2/36 [00:23<06:32, 11.55s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  8%|▊         | 3/36 [00:34<06:16, 11.41s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 11%|█         | 4/36 [00:45<05:59, 11.23s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 14%|█▍        | 5/36 [00:56<05:48, 11.25s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHSOcEhH4mlb"
      },
      "outputs": [],
      "source": [
        "###  CBLOF RAW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A--j-9Cu4mlb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-D3nCuXX4mlb"
      },
      "outputs": [],
      "source": [
        "df_raw_train = pd.concat([X_train.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_train], axis=1)\n",
        "df_raw_test = pd.concat([X_test.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "8Zr57GFE4mlb"
      },
      "outputs": [],
      "source": [
        "raw_benign_train_samples = df_raw_train[df_raw_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "raw_normal_train_samples = df_raw_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "raw_train_labels = df_raw_train[\"Label\"]\n",
        "raw_test_labels = df_raw_test[\"Label\"]\n",
        "\n",
        "raw_test_samples = df_raw_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "u_l1Vz8S4mlb",
        "outputId": "c1b8d03c-7105-42d9-f49a-bba4ff4905a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 7/36 [00:01<00:05,  5.27it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 22%|██▏       | 8/36 [00:01<00:05,  5.10it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 25%|██▌       | 9/36 [00:01<00:05,  5.02it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 28%|██▊       | 10/36 [00:01<00:05,  4.95it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 31%|███       | 11/36 [00:02<00:05,  4.88it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 33%|███▎      | 12/36 [00:02<00:04,  4.85it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 36%|███▌      | 13/36 [00:02<00:04,  4.80it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 39%|███▉      | 14/36 [00:02<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 42%|████▏     | 15/36 [00:03<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 44%|████▍     | 16/36 [00:03<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 47%|████▋     | 17/36 [00:03<00:03,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 50%|█████     | 18/36 [00:03<00:03,  4.79it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 53%|█████▎    | 19/36 [00:03<00:03,  4.74it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 56%|█████▌    | 20/36 [00:04<00:03,  4.69it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 58%|█████▊    | 21/36 [00:04<00:03,  4.65it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 61%|██████    | 22/36 [00:04<00:03,  4.60it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 64%|██████▍   | 23/36 [00:04<00:02,  4.36it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 67%|██████▋   | 24/36 [00:05<00:02,  4.40it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 69%|██████▉   | 25/36 [00:05<00:02,  4.45it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 72%|███████▏  | 26/36 [00:05<00:02,  4.46it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 75%|███████▌  | 27/36 [00:05<00:02,  4.48it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 78%|███████▊  | 28/36 [00:05<00:01,  4.42it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 81%|████████  | 29/36 [00:06<00:01,  4.41it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 83%|████████▎ | 30/36 [00:06<00:01,  4.47it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 86%|████████▌ | 31/36 [00:06<00:01,  4.45it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 89%|████████▉ | 32/36 [00:06<00:00,  4.43it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 92%|█████████▏| 33/36 [00:07<00:00,  4.43it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 94%|█████████▍| 34/36 [00:07<00:00,  4.44it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 97%|█████████▋| 35/36 [00:07<00:00,  4.40it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.2}\n",
            "0.3971858513564739\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0294    0.7949    0.0566        39\n",
            "           1     0.9945    0.5864    0.7378      2478\n",
            "\n",
            "    accuracy                         0.5896      2517\n",
            "   macro avg     0.5119    0.6906    0.3972      2517\n",
            "weighted avg     0.9796    0.5896    0.7272      2517\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-_InJ1-4mlc",
        "outputId": "e22139e6-d1cf-46e1-adf3-f0dc9b499244"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [20:42<00:00, 34.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 2}\n",
            "0.8618432811826696\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9591    0.9806    0.9697    499068\n",
            "           1     0.8287    0.6916    0.7540     67744\n",
            "\n",
            "    accuracy                         0.9461    566812\n",
            "   macro avg     0.8939    0.8361    0.8618    566812\n",
            "weighted avg     0.9435    0.9461    0.9439    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GneWZNtq4mlc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd0-H7UT4mlc"
      },
      "outputs": [],
      "source": [
        "# HBOS  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a34ZbzAX4mld"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDquxErU4mld"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG5Hcs9r4mld"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLBIT-Rc4mld",
        "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [19:29<00:00, 32.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.01}\n",
            "0.945069359337394\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9845    0.9897    0.9871    996643\n",
            "           1     0.9213    0.8855    0.9030    135488\n",
            "\n",
            "    accuracy                         0.9772   1132131\n",
            "   macro avg     0.9529    0.9376    0.9451   1132131\n",
            "weighted avg     0.9769    0.9772    0.9770   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.hbos import HBOS\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDcX0mma4mld",
        "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [21:10<00:00, 35.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.1}\n",
            "0.9189314026948445\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9705    0.9945    0.9824    996643\n",
            "           1     0.9503    0.7779    0.8555    135488\n",
            "\n",
            "    accuracy                         0.9686   1132131\n",
            "   macro avg     0.9604    0.8862    0.9189   1132131\n",
            "weighted avg     0.9681    0.9686    0.9672   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRUOrQqB4mle"
      },
      "outputs": [],
      "source": [
        "##  HBOS  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sZfAnER4mle",
        "outputId": "6e9cb145-8540-4aa7-8ed1-fc9aca495b07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [02:09<00:00,  3.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 30, 'con': 0.04}\n",
            "0.8627757960209628\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9715    0.9601    0.9658    499068\n",
            "           1     0.7294    0.7928    0.7598     67744\n",
            "\n",
            "    accuracy                         0.9401    566812\n",
            "   macro avg     0.8505    0.8765    0.8628    566812\n",
            "weighted avg     0.9426    0.9401    0.9412    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5A-gLN34mle",
        "outputId": "8a6dfd26-a45b-4ce3-8d85-1b61652e7f90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [02:14<00:00,  3.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 5}\n",
            "0.7882018992795334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9766    0.8943    0.9337    499068\n",
            "           1     0.5197    0.8422    0.6427     67744\n",
            "\n",
            "    accuracy                         0.8881    566812\n",
            "   macro avg     0.7481    0.8683    0.7882    566812\n",
            "weighted avg     0.9220    0.8881    0.8989    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0ZCfgyi4mle"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbDOqrcy4mle"
      },
      "outputs": [],
      "source": [
        "##  PCA  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDCu7S6i4mle"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nga82Fw_4mle",
        "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [29:47<00:00, 49.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.001}\n",
            "0.9442956641768174\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9770    0.9988    0.9878    996643\n",
            "           1     0.9896    0.8267    0.9008    135488\n",
            "\n",
            "    accuracy                         0.9782   1132131\n",
            "   macro avg     0.9833    0.9127    0.9443   1132131\n",
            "weighted avg     0.9785    0.9782    0.9774   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.pca import PCA\n",
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg6AcAUW4mlf",
        "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [32:26<00:00, 54.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.1}\n",
            "0.9256946497974641\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9723    0.9955    0.9838    996643\n",
            "           1     0.9598    0.7916    0.8676    135488\n",
            "\n",
            "    accuracy                         0.9711   1132131\n",
            "   macro avg     0.9661    0.8935    0.9257   1132131\n",
            "weighted avg     0.9708    0.9711    0.9699   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSoyZpDu4mlf"
      },
      "outputs": [],
      "source": [
        "##  PCA  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hKgicW14mlf",
        "outputId": "16c93b66-4eac-4d40-d5ce-96f3b3a5b3bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [07:28<00:00, 12.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.1}\n",
            "0.7684270275042566\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9639    0.9009    0.9313    499068\n",
            "           1     0.5071    0.7513    0.6055     67744\n",
            "\n",
            "    accuracy                         0.8830    566812\n",
            "   macro avg     0.7355    0.8261    0.7684    566812\n",
            "weighted avg     0.9093    0.8830    0.8924    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples)\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAdfwnlP4mlf",
        "outputId": "ddc9c2b4-a3b6-4ab6-cc74-7ed93ca23d22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [08:04<00:00, 13.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 10}\n",
            "0.7376147683157477\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9622    0.8744    0.9162    499068\n",
            "           1     0.4466    0.7471    0.5590     67744\n",
            "\n",
            "    accuracy                         0.8591    566812\n",
            "   macro avg     0.7044    0.8107    0.7376    566812\n",
            "weighted avg     0.9006    0.8591    0.8735    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples)\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdfI45oD4mlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSNV8IRT4mlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi8SO3tL4mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D0m4vb04mlg",
        "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [3:09:47<00:00, 474.46s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.001}\n",
            "0.9538863735449246\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9805    0.9992    0.9897    996643\n",
            "           1     0.9928    0.8538    0.9180    135488\n",
            "\n",
            "    accuracy                         0.9818   1132131\n",
            "   macro avg     0.9866    0.9265    0.9539   1132131\n",
            "weighted avg     0.9820    0.9818    0.9812   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCj-3u4t4mlg",
        "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [3:31:56<00:00, 529.86s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 50, 'con': 0.2}\n",
            "0.8110535459623227\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9878    0.8952    0.9392    996643\n",
            "           1     0.5436    0.9184    0.6829    135488\n",
            "\n",
            "    accuracy                         0.8979   1132131\n",
            "   macro avg     0.7657    0.9068    0.8111   1132131\n",
            "weighted avg     0.9346    0.8979    0.9085   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOIn_Kr44mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_60yAo34mlg",
        "outputId": "354e56cd-ee22-4538-ba6f-43c1d67eb648"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [19:12<00:00, 48.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.05}\n",
            "0.8176793439704795\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9599    0.9494    0.9547    499068\n",
            "           1     0.6553    0.7082    0.6807     67744\n",
            "\n",
            "    accuracy                         0.9206    566812\n",
            "   macro avg     0.8076    0.8288    0.8177    566812\n",
            "weighted avg     0.9235    0.9206    0.9219    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples.to_numpy())\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xNKBA7X4mlh",
        "outputId": "cd0ee1c5-5394-4e2b-efde-1f58bf922282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [20:38<00:00, 51.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 100}\n",
            "0.7409370706714709\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9633    0.8755    0.9173    499068\n",
            "           1     0.4512    0.7539    0.5646     67744\n",
            "\n",
            "    accuracy                         0.8610    566812\n",
            "   macro avg     0.7072    0.8147    0.7409    566812\n",
            "weighted avg     0.9021    0.8610    0.8751    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples.to_numpy())\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYBqJ8y14mlh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gnn_cuda_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
