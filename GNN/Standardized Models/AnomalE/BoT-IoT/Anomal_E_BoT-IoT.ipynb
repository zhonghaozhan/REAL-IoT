{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hjc3iIihKLn-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn import preprocessing\n",
        "from dgl.data import DGLDataset\n",
        "import dgl\n",
        "import time\n",
        "import networkx as nx\n",
        "import category_encoders as ce\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import torch\n",
        "import tqdm\n",
        "import math\n",
        "\n",
        "from typing import *\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "import socket\n",
        "import struct\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SvWHb_BpKsLq"
      },
      "outputs": [],
      "source": [
        "file_name = \"/media/ssd/test/standardized-datasets/netflow/nf_bot_iot_v2_reduced_standardized.csv\"\n",
        "data = pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "fqly1y-LMwYS",
        "outputId": "18cca6c8-8a93-46c4-ffa1-9d21ebe843b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Label\n",
              "1    339853\n",
              "0      5403\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3t4OREvSM33h"
      },
      "outputs": [],
      "source": [
        "data.rename(columns=lambda x: x.strip(), inplace=True)\n",
        "data['IPV4_SRC_ADDR'] = data[\"IPV4_SRC_ADDR\"].apply(str)\n",
        "data['L4_SRC_PORT'] = data[\"L4_SRC_PORT\"].apply(str)\n",
        "data['IPV4_DST_ADDR'] = data[\"IPV4_DST_ADDR\"].apply(str)\n",
        "data['L4_DST_PORT'] = data[\"L4_DST_PORT\"].apply(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bTtHq0XqNXxI"
      },
      "outputs": [],
      "source": [
        "data.drop(columns=[\"L4_SRC_PORT\", \"L4_DST_PORT\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUNIP-8zNkn9",
        "outputId": "34de637f-b644-4249-c3fd-cd19bb3bbde2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['DDoS', 'DoS', 'Reconnaissance', 'Benign', 'Theft'], dtype=object)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.Attack.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AlPa58fVN7gB"
      },
      "outputs": [],
      "source": [
        "data = data.groupby(by='Attack').sample(frac=0.1, random_state=13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "lcfAP6ViOp-J",
        "outputId": "3641324e-a78b-46bb-c3a4-8af04a7f9449"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>Label</th>\n",
              "      <th>flow_id</th>\n",
              "      <th>dataset_source</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Attack</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Benign</th>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>...</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "      <td>540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DDoS</th>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>...</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "      <td>16499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DoS</th>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>...</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "      <td>15006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reconnaissance</th>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>...</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "      <td>2359</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Theft</th>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>...</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "      <td>122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 44 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                IPV4_SRC_ADDR  IPV4_DST_ADDR  PROTOCOL  L7_PROTO  IN_BYTES  \\\n",
              "Attack                                                                       \n",
              "Benign                    540            540       540       540       540   \n",
              "DDoS                    16499          16499     16499     16499     16499   \n",
              "DoS                     15006          15006     15006     15006     15006   \n",
              "Reconnaissance           2359           2359      2359      2359      2359   \n",
              "Theft                     122            122       122       122       122   \n",
              "\n",
              "                IN_PKTS  OUT_BYTES  OUT_PKTS  TCP_FLAGS  CLIENT_TCP_FLAGS  \\\n",
              "Attack                                                                      \n",
              "Benign              540        540       540        540               540   \n",
              "DDoS              16499      16499     16499      16499             16499   \n",
              "DoS               15006      15006     15006      15006             15006   \n",
              "Reconnaissance     2359       2359      2359       2359              2359   \n",
              "Theft               122        122       122        122               122   \n",
              "\n",
              "                ...  TCP_WIN_MAX_OUT  ICMP_TYPE  ICMP_IPV4_TYPE  DNS_QUERY_ID  \\\n",
              "Attack          ...                                                             \n",
              "Benign          ...              540        540             540           540   \n",
              "DDoS            ...            16499      16499           16499         16499   \n",
              "DoS             ...            15006      15006           15006         15006   \n",
              "Reconnaissance  ...             2359       2359            2359          2359   \n",
              "Theft           ...              122        122             122           122   \n",
              "\n",
              "                DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  Label  \\\n",
              "Attack                                                                        \n",
              "Benign                     540             540                   540    540   \n",
              "DDoS                     16499           16499                 16499  16499   \n",
              "DoS                      15006           15006                 15006  15006   \n",
              "Reconnaissance            2359            2359                  2359   2359   \n",
              "Theft                      122             122                   122    122   \n",
              "\n",
              "                flow_id  dataset_source  \n",
              "Attack                                   \n",
              "Benign              540             540  \n",
              "DDoS              16499           16499  \n",
              "DoS               15006           15006  \n",
              "Reconnaissance     2359            2359  \n",
              "Theft               122             122  \n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.groupby(by=\"Attack\").count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FqRx5xCPOuv8"
      },
      "outputs": [],
      "source": [
        "X = data.drop(columns=[\"Attack\", \"Label\"])\n",
        "y = data[[\"Attack\", \"Label\"]]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=13, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bPfakXplPGGx"
      },
      "outputs": [],
      "source": [
        "encoder = ce.TargetEncoder(cols=['TCP_FLAGS','L7_PROTO','PROTOCOL',\n",
        "                                  'CLIENT_TCP_FLAGS','SERVER_TCP_FLAGS','ICMP_TYPE',\n",
        "                                  'ICMP_IPV4_TYPE','DNS_QUERY_ID','DNS_QUERY_TYPE',\n",
        "                                  'FTP_COMMAND_RET_CODE'])\n",
        "encoder.fit(X_train, y_train.Label)\n",
        "\n",
        "# Transform on training set\n",
        "X_train = encoder.transform(X_train)\n",
        "\n",
        "# Transform on testing set\n",
        "X_test = encoder.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ibyOfV-8PouK"
      },
      "outputs": [],
      "source": [
        "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X_train.fillna(0, inplace=True)\n",
        "X_test.fillna(0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'dataset_source' in X_train.columns:\n",
        "    X_train = X_train.drop(columns=['dataset_source'])\n",
        "if 'dataset_source' in X_test.columns:\n",
        "    X_test = X_test.drop(columns=['dataset_source'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "asDnsSIWPee0"
      },
      "outputs": [],
      "source": [
        "scaler = Normalizer()\n",
        "cols_to_norm = list(set(list(X_train.iloc[:, 2:].columns))) # Ignore first two as the represents IP addresses\n",
        "scaler.fit(X_train[cols_to_norm])\n",
        "\n",
        "# Transform on training set\n",
        "X_train[cols_to_norm] = scaler.transform(X_train[cols_to_norm])\n",
        "X_train['h'] = X_train.iloc[:, 2:].values.tolist()\n",
        "\n",
        "# Transform on testing set\n",
        "X_test[cols_to_norm] = scaler.transform(X_test[cols_to_norm])\n",
        "X_test['h'] = X_test.iloc[:, 2:].values.tolist()\n",
        "\n",
        "train = pd.concat([X_train, y_train], axis=1)\n",
        "test = pd.concat([X_test, y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "hErQbsnrPluV",
        "outputId": "c4dbe223-89d5-48f5-800d-16512a77e66c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IPV4_SRC_ADDR</th>\n",
              "      <th>IPV4_DST_ADDR</th>\n",
              "      <th>PROTOCOL</th>\n",
              "      <th>L7_PROTO</th>\n",
              "      <th>IN_BYTES</th>\n",
              "      <th>IN_PKTS</th>\n",
              "      <th>OUT_BYTES</th>\n",
              "      <th>OUT_PKTS</th>\n",
              "      <th>TCP_FLAGS</th>\n",
              "      <th>CLIENT_TCP_FLAGS</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP_WIN_MAX_IN</th>\n",
              "      <th>TCP_WIN_MAX_OUT</th>\n",
              "      <th>ICMP_TYPE</th>\n",
              "      <th>ICMP_IPV4_TYPE</th>\n",
              "      <th>DNS_QUERY_ID</th>\n",
              "      <th>DNS_QUERY_TYPE</th>\n",
              "      <th>DNS_TTL_ANSWER</th>\n",
              "      <th>FTP_COMMAND_RET_CODE</th>\n",
              "      <th>flow_id</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32465</th>\n",
              "      <td>192.168.100.149</td>\n",
              "      <td>192.168.100.3</td>\n",
              "      <td>2.315639e-07</td>\n",
              "      <td>2.325657e-07</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>9.302630e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.312090e-07</td>\n",
              "      <td>2.309911e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.284059e-07</td>\n",
              "      <td>2.284061e-07</td>\n",
              "      <td>2.291084e-07</td>\n",
              "      <td>2.291084e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.289283e-07</td>\n",
              "      <td>0.007550</td>\n",
              "      <td>[2.31563909593547e-07, 2.3256574358850048e-07,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92452</th>\n",
              "      <td>192.168.100.147</td>\n",
              "      <td>192.168.100.3</td>\n",
              "      <td>2.314886e-07</td>\n",
              "      <td>2.324901e-07</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>4.649802e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.311338e-07</td>\n",
              "      <td>2.309160e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.283316e-07</td>\n",
              "      <td>2.283318e-07</td>\n",
              "      <td>2.290339e-07</td>\n",
              "      <td>2.290339e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.288538e-07</td>\n",
              "      <td>0.021494</td>\n",
              "      <td>[2.314885771112382e-07, 2.3249008518907517e-07...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282215</th>\n",
              "      <td>192.168.100.149</td>\n",
              "      <td>192.168.100.6</td>\n",
              "      <td>2.189301e-07</td>\n",
              "      <td>2.200728e-07</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>4.496294e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.248147e-07</td>\n",
              "      <td>2.237869e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.207934e-07</td>\n",
              "      <td>2.207936e-07</td>\n",
              "      <td>2.214726e-07</td>\n",
              "      <td>2.214726e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.212985e-07</td>\n",
              "      <td>0.063446</td>\n",
              "      <td>[2.1893013329341758e-07, 2.2007283033213947e-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10934</th>\n",
              "      <td>192.168.100.148</td>\n",
              "      <td>192.168.100.5</td>\n",
              "      <td>2.193752e-07</td>\n",
              "      <td>2.205202e-07</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>4.505434e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.252717e-07</td>\n",
              "      <td>2.242418e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.212423e-07</td>\n",
              "      <td>2.212425e-07</td>\n",
              "      <td>2.219228e-07</td>\n",
              "      <td>2.219228e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.217483e-07</td>\n",
              "      <td>0.002463</td>\n",
              "      <td>[2.1937517019218034e-07, 2.2052019008312312e-0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143756</th>\n",
              "      <td>192.168.100.150</td>\n",
              "      <td>192.168.100.7</td>\n",
              "      <td>2.192631e-07</td>\n",
              "      <td>2.204076e-07</td>\n",
              "      <td>0.000063</td>\n",
              "      <td>4.503133e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.251566e-07</td>\n",
              "      <td>2.241272e-07</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000115</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.211293e-07</td>\n",
              "      <td>2.211295e-07</td>\n",
              "      <td>2.218094e-07</td>\n",
              "      <td>2.218094e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.216351e-07</td>\n",
              "      <td>0.032368</td>\n",
              "      <td>[2.1926313388399291e-07, 2.2040756900592438e-0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 43 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          IPV4_SRC_ADDR  IPV4_DST_ADDR      PROTOCOL      L7_PROTO  IN_BYTES  \\\n",
              "32465   192.168.100.149  192.168.100.3  2.315639e-07  2.325657e-07  0.000026   \n",
              "92452   192.168.100.147  192.168.100.3  2.314886e-07  2.324901e-07  0.000013   \n",
              "282215  192.168.100.149  192.168.100.6  2.189301e-07  2.200728e-07  0.000063   \n",
              "10934   192.168.100.148  192.168.100.5  2.193752e-07  2.205202e-07  0.000063   \n",
              "143756  192.168.100.150  192.168.100.7  2.192631e-07  2.204076e-07  0.000063   \n",
              "\n",
              "             IN_PKTS  OUT_BYTES  OUT_PKTS     TCP_FLAGS  CLIENT_TCP_FLAGS  \\\n",
              "32465   9.302630e-07        0.0       0.0  2.312090e-07      2.309911e-07   \n",
              "92452   4.649802e-07        0.0       0.0  2.311338e-07      2.309160e-07   \n",
              "282215  4.496294e-07        0.0       0.0  2.248147e-07      2.237869e-07   \n",
              "10934   4.505434e-07        0.0       0.0  2.252717e-07      2.242418e-07   \n",
              "143756  4.503133e-07        0.0       0.0  2.251566e-07      2.241272e-07   \n",
              "\n",
              "        ...  TCP_WIN_MAX_IN  TCP_WIN_MAX_OUT     ICMP_TYPE  ICMP_IPV4_TYPE  \\\n",
              "32465   ...        0.000000              0.0  2.284059e-07    2.284061e-07   \n",
              "92452   ...        0.000000              0.0  2.283316e-07    2.283318e-07   \n",
              "282215  ...        0.000115              0.0  2.207934e-07    2.207936e-07   \n",
              "10934   ...        0.000115              0.0  2.212423e-07    2.212425e-07   \n",
              "143756  ...        0.000115              0.0  2.211293e-07    2.211295e-07   \n",
              "\n",
              "        DNS_QUERY_ID  DNS_QUERY_TYPE  DNS_TTL_ANSWER  FTP_COMMAND_RET_CODE  \\\n",
              "32465   2.291084e-07    2.291084e-07             0.0          2.289283e-07   \n",
              "92452   2.290339e-07    2.290339e-07             0.0          2.288538e-07   \n",
              "282215  2.214726e-07    2.214726e-07             0.0          2.212985e-07   \n",
              "10934   2.219228e-07    2.219228e-07             0.0          2.217483e-07   \n",
              "143756  2.218094e-07    2.218094e-07             0.0          2.216351e-07   \n",
              "\n",
              "         flow_id                                                  h  \n",
              "32465   0.007550  [2.31563909593547e-07, 2.3256574358850048e-07,...  \n",
              "92452   0.021494  [2.314885771112382e-07, 2.3249008518907517e-07...  \n",
              "282215  0.063446  [2.1893013329341758e-07, 2.2007283033213947e-0...  \n",
              "10934   0.002463  [2.1937517019218034e-07, 2.2052019008312312e-0...  \n",
              "143756  0.032368  [2.1926313388399291e-07, 2.2040756900592438e-0...  \n",
              "\n",
              "[5 rows x 43 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "d_tLtK4WPtrF"
      },
      "outputs": [],
      "source": [
        "lab_enc = preprocessing.LabelEncoder()\n",
        "lab_enc.fit(data[\"Attack\"])\n",
        "\n",
        "# Transform on training set\n",
        "train[\"Attack\"] = lab_enc.transform(train[\"Attack\"])\n",
        "\n",
        "# Transform on testing set\n",
        "test[\"Attack\"] = lab_enc.transform(test[\"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "8yaicjecP1fZ"
      },
      "outputs": [],
      "source": [
        "# Training graph\n",
        "\n",
        "train_g = nx.from_pandas_edgelist(train, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "train_g = train_g.to_directed()\n",
        "train_g = dgl.from_networkx(train_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([train_g.number_of_nodes(),\n",
        "train_g.edata['h'].shape[1]])\n",
        "train_g.ndata['h'] = nfeat_weight\n",
        "\n",
        "# Testing graph\n",
        "test_g = nx.from_pandas_edgelist(test, \"IPV4_SRC_ADDR\", \"IPV4_DST_ADDR\",\n",
        "            [\"h\", \"Label\", \"Attack\"], create_using=nx.MultiGraph())\n",
        "\n",
        "test_g = test_g.to_directed()\n",
        "test_g = dgl.from_networkx(test_g, edge_attrs=['h', 'Attack', 'Label'])\n",
        "nfeat_weight = torch.ones([test_g.number_of_nodes(),\n",
        "test_g.edata['h'].shape[1]])\n",
        "test_g.ndata['h'] = nfeat_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PUV6DgJ9QRaP"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl.function as fn\n",
        "import tqdm\n",
        "import gc\n",
        "\n",
        "class SAGELayer(nn.Module):\n",
        "    def __init__(self, ndim_in, edims, ndim_out, activation):\n",
        "      super(SAGELayer, self).__init__()\n",
        "      self.W_apply = nn.Linear(ndim_in + edims , ndim_out)\n",
        "      self.activation = F.relu\n",
        "      self.W_edge = nn.Linear(128 * 2, 256)\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      gain = nn.init.calculate_gain('relu')\n",
        "      nn.init.xavier_uniform_(self.W_apply.weight, gain=gain)\n",
        "\n",
        "    def message_func(self, edges):\n",
        "      return {'m':  edges.data['h']}\n",
        "\n",
        "    def forward(self, g_dgl, nfeats, efeats):\n",
        "      with g_dgl.local_scope():\n",
        "        g = g_dgl\n",
        "        g.ndata['h'] = nfeats\n",
        "        g.edata['h'] = efeats\n",
        "        g.update_all(self.message_func, fn.mean('m', 'h_neigh'))\n",
        "        g.ndata['h'] = F.relu(self.W_apply(torch.cat([g.ndata['h'], g.ndata['h_neigh']], 2)))\n",
        "\n",
        "        # Compute edge embeddings\n",
        "        u, v = g.edges()\n",
        "        edge = self.W_edge(torch.cat((g.srcdata['h'][u], g.dstdata['h'][v]), 2))\n",
        "        return g.ndata['h'], edge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "_xo-3K4QRGqc"
      },
      "outputs": [],
      "source": [
        "class SAGE(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim,  activation):\n",
        "      super(SAGE, self).__init__()\n",
        "      self.layers = nn.ModuleList()\n",
        "      self.layers.append(SAGELayer(ndim_in, edim, 128, F.relu))\n",
        "\n",
        "    def forward(self, g, nfeats, efeats, corrupt=False):\n",
        "      if corrupt:\n",
        "        e_perm = torch.randperm(g.number_of_edges())\n",
        "        #n_perm = torch.randperm(g.number_of_nodes())\n",
        "        efeats = efeats[e_perm]\n",
        "        #nfeats = nfeats[n_perm]\n",
        "      for i, layer in enumerate(self.layers):\n",
        "        #nfeats = layer(g, nfeats, efeats)\n",
        "        nfeats, e_feats = layer(g, nfeats, efeats)\n",
        "      #return nfeats.sum(1)\n",
        "      return nfeats.sum(1), e_feats.sum(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6uuxRtLuRJQL"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, n_hidden):\n",
        "      super(Discriminator, self).__init__()\n",
        "      self.weight = nn.Parameter(torch.Tensor(n_hidden, n_hidden))\n",
        "      self.reset_parameters()\n",
        "\n",
        "    def uniform(self, size, tensor):\n",
        "      bound = 1.0 / math.sqrt(size)\n",
        "      if tensor is not None:\n",
        "        tensor.data.uniform_(-bound, bound)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "      size = self.weight.size(0)\n",
        "      self.uniform(size, self.weight)\n",
        "\n",
        "    def forward(self, features, summary):\n",
        "      features = torch.matmul(features, torch.matmul(self.weight, summary))\n",
        "      return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ZPbVjlCyRUco"
      },
      "outputs": [],
      "source": [
        "class DGI(nn.Module):\n",
        "    def __init__(self, ndim_in, ndim_out, edim, activation):\n",
        "      super(DGI, self).__init__()\n",
        "      self.encoder = SAGE(ndim_in, ndim_out, edim,  F.relu)\n",
        "      #self.discriminator = Discriminator(128)\n",
        "      self.discriminator = Discriminator(256)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "      self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def forward(self, g, n_features, e_features):\n",
        "      positive = self.encoder(g, n_features, e_features, corrupt=False)\n",
        "      negative = self.encoder(g, n_features, e_features, corrupt=True)\n",
        "\n",
        "      positive = positive[1]\n",
        "      negative = negative[1]\n",
        "\n",
        "      summary = torch.sigmoid(positive.mean(dim=0))\n",
        "\n",
        "      positive = self.discriminator(positive, summary)\n",
        "      negative = self.discriminator(negative, summary)\n",
        "\n",
        "      l1 = self.loss(positive, torch.ones_like(positive))\n",
        "      l2 = self.loss(negative, torch.zeros_like(negative))\n",
        "\n",
        "      return l1 + l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "sKnfpWFMR19u"
      },
      "outputs": [],
      "source": [
        "ndim_in = train_g.ndata['h'].shape[1]\n",
        "hidden_features = 128\n",
        "ndim_out = 128\n",
        "num_layers = 1\n",
        "edim = train_g.edata['h'].shape[1]\n",
        "learning_rate = 1e-3\n",
        "epochs = 4000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "aSl_9qY8SbA0"
      },
      "outputs": [],
      "source": [
        "dgi = DGI(ndim_in,\n",
        "    ndim_out,\n",
        "    edim,\n",
        "    F.relu)\n",
        "\n",
        "dgi = dgi.to(device)\n",
        "\n",
        "dgi_optimizer = torch.optim.Adam(dgi.parameters(),\n",
        "                lr=1e-3,\n",
        "                weight_decay=0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "9K6_cOiWSdJA"
      },
      "outputs": [],
      "source": [
        "# Format node and edge features for E-GraphSAGE\n",
        "train_g.ndata['h'] = torch.reshape(train_g.ndata['h'],\n",
        "                                   (train_g.ndata['h'].shape[0], 1,\n",
        "                                    train_g.ndata['h'].shape[1]))\n",
        "\n",
        "train_g.edata['h'] = torch.reshape(train_g.edata['h'],\n",
        "                                   (train_g.edata['h'].shape[0], 1,\n",
        "                                    train_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "O44auIyWSexg"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "train_g = train_g.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gZtafIdxSheN"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/numpy/core/_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 00000 | Time(s) nan | Loss 1.3871 | ETputs(KTEPS) nan\n",
            "Epoch 00050 | Time(s) 0.0328 | Loss 1.3936 | ETputs(KTEPS) 1475.07\n",
            "Epoch 00100 | Time(s) 0.0328 | Loss 1.3863 | ETputs(KTEPS) 1472.09\n",
            "Epoch 00150 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1470.48\n",
            "Epoch 00200 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1462.41\n",
            "Epoch 00250 | Time(s) 0.0332 | Loss 1.3863 | ETputs(KTEPS) 1454.27\n",
            "Epoch 00300 | Time(s) 0.0332 | Loss 1.3863 | ETputs(KTEPS) 1456.42\n",
            "Epoch 00350 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1458.61\n",
            "Epoch 00400 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1460.61\n",
            "Epoch 00450 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1460.62\n",
            "Epoch 00500 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1460.76\n",
            "Epoch 00550 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1460.71\n",
            "Epoch 00600 | Time(s) 0.0331 | Loss 1.3862 | ETputs(KTEPS) 1460.61\n",
            "Epoch 00650 | Time(s) 0.0331 | Loss 1.3862 | ETputs(KTEPS) 1460.53\n",
            "Epoch 00700 | Time(s) 0.0331 | Loss 1.3862 | ETputs(KTEPS) 1460.14\n",
            "Epoch 00750 | Time(s) 0.0331 | Loss 1.3862 | ETputs(KTEPS) 1460.38\n",
            "Epoch 00800 | Time(s) 0.0331 | Loss 1.3862 | ETputs(KTEPS) 1458.51\n",
            "Epoch 00850 | Time(s) 0.0332 | Loss 1.3862 | ETputs(KTEPS) 1457.21\n",
            "Epoch 00900 | Time(s) 0.0332 | Loss 1.3862 | ETputs(KTEPS) 1456.08\n",
            "Epoch 00950 | Time(s) 0.0332 | Loss 1.3861 | ETputs(KTEPS) 1454.63\n",
            "Epoch 01000 | Time(s) 0.0332 | Loss 1.3861 | ETputs(KTEPS) 1454.29\n",
            "Epoch 01050 | Time(s) 0.0332 | Loss 1.3861 | ETputs(KTEPS) 1454.95\n",
            "Epoch 01100 | Time(s) 0.0332 | Loss 1.3857 | ETputs(KTEPS) 1455.62\n",
            "Epoch 01150 | Time(s) 0.0332 | Loss 1.3862 | ETputs(KTEPS) 1456.20\n",
            "Epoch 01200 | Time(s) 0.0332 | Loss 1.3862 | ETputs(KTEPS) 1455.37\n",
            "Epoch 01250 | Time(s) 0.0332 | Loss 1.3862 | ETputs(KTEPS) 1454.34\n",
            "Epoch 01300 | Time(s) 0.0332 | Loss 1.3863 | ETputs(KTEPS) 1454.50\n",
            "Epoch 01350 | Time(s) 0.0332 | Loss 1.3863 | ETputs(KTEPS) 1455.08\n",
            "Epoch 01400 | Time(s) 0.0332 | Loss 1.3863 | ETputs(KTEPS) 1455.72\n",
            "Epoch 01450 | Time(s) 0.0332 | Loss 1.3863 | ETputs(KTEPS) 1456.37\n",
            "Epoch 01500 | Time(s) 0.0332 | Loss 1.3863 | ETputs(KTEPS) 1456.96\n",
            "Epoch 01550 | Time(s) 0.0332 | Loss 1.3862 | ETputs(KTEPS) 1457.54\n",
            "Epoch 01600 | Time(s) 0.0332 | Loss 1.3862 | ETputs(KTEPS) 1458.00\n",
            "Epoch 01650 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1458.22\n",
            "Epoch 01700 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1458.52\n",
            "Epoch 01750 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1459.01\n",
            "Epoch 01800 | Time(s) 0.0331 | Loss 1.3862 | ETputs(KTEPS) 1459.38\n",
            "Epoch 01850 | Time(s) 0.0331 | Loss 1.3862 | ETputs(KTEPS) 1459.79\n",
            "Epoch 01900 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1460.19\n",
            "Epoch 01950 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1460.60\n",
            "Epoch 02000 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1461.04\n",
            "Epoch 02050 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1461.44\n",
            "Epoch 02100 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1461.94\n",
            "Epoch 02150 | Time(s) 0.0331 | Loss 1.3863 | ETputs(KTEPS) 1462.40\n",
            "Epoch 02200 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1462.76\n",
            "Epoch 02250 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1463.10\n",
            "Epoch 02300 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1463.38\n",
            "Epoch 02350 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1463.71\n",
            "Epoch 02400 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1464.08\n",
            "Epoch 02450 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1464.33\n",
            "Epoch 02500 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1464.48\n",
            "Epoch 02550 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1463.80\n",
            "Epoch 02600 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1463.88\n",
            "Epoch 02650 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1464.10\n",
            "Epoch 02700 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1464.51\n",
            "Epoch 02750 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1464.92\n",
            "Epoch 02800 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1465.21\n",
            "Epoch 02850 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1465.54\n",
            "Epoch 02900 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1465.96\n",
            "Epoch 02950 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1466.37\n",
            "Epoch 03000 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1466.66\n",
            "Epoch 03050 | Time(s) 0.0330 | Loss 1.3863 | ETputs(KTEPS) 1466.84\n",
            "Epoch 03100 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1467.09\n",
            "Epoch 03150 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1467.29\n",
            "Epoch 03200 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1467.50\n",
            "Epoch 03250 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1467.75\n",
            "Epoch 03300 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.14\n",
            "Epoch 03350 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.33\n",
            "Epoch 03400 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.55\n",
            "Epoch 03450 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.75\n",
            "Epoch 03500 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.95\n",
            "Epoch 03550 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.72\n",
            "Epoch 03600 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.30\n",
            "Epoch 03650 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.51\n",
            "Epoch 03700 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1468.82\n",
            "Epoch 03750 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1469.20\n",
            "Epoch 03800 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1469.56\n",
            "Epoch 03850 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1469.84\n",
            "Epoch 03900 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1470.02\n",
            "Epoch 03950 | Time(s) 0.0329 | Loss 1.3863 | ETputs(KTEPS) 1470.17\n"
          ]
        }
      ],
      "source": [
        "cnt_wait = 0\n",
        "best = 1e9\n",
        "best_t = 0\n",
        "dur = []\n",
        "node_features = train_g.ndata['h']\n",
        "edge_features = train_g.edata['h']\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    dgi.train()\n",
        "    if epoch >= 3:\n",
        "        t0 = time.time()\n",
        "\n",
        "    dgi_optimizer.zero_grad()\n",
        "    loss = dgi(train_g, node_features, edge_features)\n",
        "    loss.backward()\n",
        "    dgi_optimizer.step()\n",
        "\n",
        "    if loss < best:\n",
        "        best = loss\n",
        "        best_t = epoch\n",
        "        cnt_wait = 0\n",
        "        torch.save(dgi.state_dict(), 'best_dgi.pkl')\n",
        "    else:\n",
        "        cnt_wait += 1\n",
        "\n",
        "  # if cnt_wait == patience:\n",
        "  #     print('Early stopping!')\n",
        "  #     break\n",
        "\n",
        "    if epoch >= 3:\n",
        "        dur.append(time.time() - t0)\n",
        "\n",
        "    if epoch % 50 == 0:\n",
        "\n",
        "        print(\"Epoch {:05d} | Time(s) {:.4f} | Loss {:.4f} | \"\n",
        "            \"ETputs(KTEPS) {:.2f}\".format(epoch, np.mean(dur),\n",
        "              loss.item(),\n",
        "              train_g.num_edges() / np.mean(dur) / 1000))\n",
        "# ... existing code ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RZ2HAQDAF-4c",
        "outputId": "79b6374d-390e-4571-df1d-ee46792480f7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15107/597080661.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  dgi.load_state_dict(torch.load('best_dgi.pkl'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dgi.load_state_dict(torch.load('best_dgi.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "6Ek16GkRStKP"
      },
      "outputs": [],
      "source": [
        "training_emb = dgi.encoder(train_g, train_g.ndata['h'], train_g.edata['h'])[1]\n",
        "training_emb = training_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-FwaBlOdS4ep"
      },
      "outputs": [],
      "source": [
        "test_g.ndata['h'] = torch.reshape(test_g.ndata['h'],\n",
        "                                   (test_g.ndata['h'].shape[0], 1,\n",
        "                                    test_g.ndata['h'].shape[1]))\n",
        "\n",
        "\n",
        "\n",
        "test_g.edata['h'] = torch.reshape(test_g.edata['h'],\n",
        "                                   (test_g.edata['h'].shape[0], 1,\n",
        "                                    test_g.edata['h'].shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SBa-rdivS6cQ"
      },
      "outputs": [],
      "source": [
        "# Convert to GPU\n",
        "test_g = test_g.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "W12WLjslS-kx"
      },
      "outputs": [],
      "source": [
        "testing_emb = dgi.encoder(test_g, test_g.ndata['h'], test_g.edata['h'])[1]\n",
        "testing_emb = testing_emb.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ERsOAMjeS_D8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.DataFrame(training_emb, )\n",
        "df_train[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        train_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_train[\"Label\"] = train_g.edata['Label'].detach().cpu().numpy()\n",
        "\n",
        "df_test = pd.DataFrame(testing_emb, )\n",
        "df_test[\"Attack\"] = lab_enc.inverse_transform(\n",
        "        test_g.edata['Attack'].detach().cpu().numpy())\n",
        "df_test[\"Label\"] = test_g.edata['Label'].detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "B8p79H9dat5T",
        "outputId": "0d6e82d8-5d02-49eb-a16f-d44e52ea3dff"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "      <th>251</th>\n",
              "      <th>252</th>\n",
              "      <th>253</th>\n",
              "      <th>254</th>\n",
              "      <th>255</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.021149</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.006471</td>\n",
              "      <td>-0.049341</td>\n",
              "      <td>0.009620</td>\n",
              "      <td>0.007508</td>\n",
              "      <td>-0.000810</td>\n",
              "      <td>-0.168524</td>\n",
              "      <td>-0.007889</td>\n",
              "      <td>0.023919</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038401</td>\n",
              "      <td>-0.013742</td>\n",
              "      <td>0.044161</td>\n",
              "      <td>-0.037521</td>\n",
              "      <td>-0.095929</td>\n",
              "      <td>-0.018112</td>\n",
              "      <td>-0.013422</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>DDoS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.021149</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.006471</td>\n",
              "      <td>-0.049341</td>\n",
              "      <td>0.009620</td>\n",
              "      <td>0.007508</td>\n",
              "      <td>-0.000810</td>\n",
              "      <td>-0.168524</td>\n",
              "      <td>-0.007889</td>\n",
              "      <td>0.023919</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038401</td>\n",
              "      <td>-0.013742</td>\n",
              "      <td>0.044161</td>\n",
              "      <td>-0.037521</td>\n",
              "      <td>-0.095929</td>\n",
              "      <td>-0.018112</td>\n",
              "      <td>-0.013422</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>DDoS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.021149</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.006471</td>\n",
              "      <td>-0.049341</td>\n",
              "      <td>0.009620</td>\n",
              "      <td>0.007508</td>\n",
              "      <td>-0.000810</td>\n",
              "      <td>-0.168524</td>\n",
              "      <td>-0.007889</td>\n",
              "      <td>0.023919</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038401</td>\n",
              "      <td>-0.013742</td>\n",
              "      <td>0.044161</td>\n",
              "      <td>-0.037521</td>\n",
              "      <td>-0.095929</td>\n",
              "      <td>-0.018112</td>\n",
              "      <td>-0.013422</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>Reconnaissance</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.021149</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.006471</td>\n",
              "      <td>-0.049341</td>\n",
              "      <td>0.009620</td>\n",
              "      <td>0.007508</td>\n",
              "      <td>-0.000810</td>\n",
              "      <td>-0.168524</td>\n",
              "      <td>-0.007889</td>\n",
              "      <td>0.023919</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038401</td>\n",
              "      <td>-0.013742</td>\n",
              "      <td>0.044161</td>\n",
              "      <td>-0.037521</td>\n",
              "      <td>-0.095929</td>\n",
              "      <td>-0.018112</td>\n",
              "      <td>-0.013422</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>DDoS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.021149</td>\n",
              "      <td>0.021297</td>\n",
              "      <td>0.006471</td>\n",
              "      <td>-0.049341</td>\n",
              "      <td>0.009620</td>\n",
              "      <td>0.007508</td>\n",
              "      <td>-0.000810</td>\n",
              "      <td>-0.168524</td>\n",
              "      <td>-0.007889</td>\n",
              "      <td>0.023919</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.038401</td>\n",
              "      <td>-0.013742</td>\n",
              "      <td>0.044161</td>\n",
              "      <td>-0.037521</td>\n",
              "      <td>-0.095929</td>\n",
              "      <td>-0.018112</td>\n",
              "      <td>-0.013422</td>\n",
              "      <td>0.001110</td>\n",
              "      <td>DDoS</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48331</th>\n",
              "      <td>0.004312</td>\n",
              "      <td>0.072504</td>\n",
              "      <td>-0.030171</td>\n",
              "      <td>0.001916</td>\n",
              "      <td>0.043860</td>\n",
              "      <td>0.004750</td>\n",
              "      <td>-0.000360</td>\n",
              "      <td>-0.164642</td>\n",
              "      <td>0.039304</td>\n",
              "      <td>-0.045633</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053657</td>\n",
              "      <td>0.076697</td>\n",
              "      <td>0.061742</td>\n",
              "      <td>-0.007181</td>\n",
              "      <td>-0.154663</td>\n",
              "      <td>0.043798</td>\n",
              "      <td>0.032555</td>\n",
              "      <td>-0.036224</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48332</th>\n",
              "      <td>0.007070</td>\n",
              "      <td>0.017005</td>\n",
              "      <td>-0.011894</td>\n",
              "      <td>0.010123</td>\n",
              "      <td>0.006845</td>\n",
              "      <td>-0.034696</td>\n",
              "      <td>-0.007742</td>\n",
              "      <td>-0.139460</td>\n",
              "      <td>-0.002645</td>\n",
              "      <td>0.059991</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.047402</td>\n",
              "      <td>0.015132</td>\n",
              "      <td>0.006021</td>\n",
              "      <td>-0.034803</td>\n",
              "      <td>-0.140990</td>\n",
              "      <td>0.049975</td>\n",
              "      <td>0.007324</td>\n",
              "      <td>-0.000731</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48333</th>\n",
              "      <td>0.008096</td>\n",
              "      <td>0.016402</td>\n",
              "      <td>-0.010737</td>\n",
              "      <td>0.010703</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>-0.034409</td>\n",
              "      <td>-0.007028</td>\n",
              "      <td>-0.139263</td>\n",
              "      <td>-0.000572</td>\n",
              "      <td>0.060527</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.046473</td>\n",
              "      <td>0.016642</td>\n",
              "      <td>0.004763</td>\n",
              "      <td>-0.035007</td>\n",
              "      <td>-0.139795</td>\n",
              "      <td>0.049656</td>\n",
              "      <td>0.006505</td>\n",
              "      <td>-0.001800</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48334</th>\n",
              "      <td>-0.009642</td>\n",
              "      <td>0.016289</td>\n",
              "      <td>-0.017025</td>\n",
              "      <td>-0.006309</td>\n",
              "      <td>0.023712</td>\n",
              "      <td>-0.038323</td>\n",
              "      <td>0.019468</td>\n",
              "      <td>-0.151655</td>\n",
              "      <td>-0.017344</td>\n",
              "      <td>0.063859</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.036864</td>\n",
              "      <td>0.006375</td>\n",
              "      <td>0.023050</td>\n",
              "      <td>-0.005733</td>\n",
              "      <td>-0.114326</td>\n",
              "      <td>0.021652</td>\n",
              "      <td>0.032550</td>\n",
              "      <td>-0.016438</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48335</th>\n",
              "      <td>0.003370</td>\n",
              "      <td>0.063518</td>\n",
              "      <td>-0.029434</td>\n",
              "      <td>0.001184</td>\n",
              "      <td>0.046182</td>\n",
              "      <td>-0.002004</td>\n",
              "      <td>-0.003866</td>\n",
              "      <td>-0.160021</td>\n",
              "      <td>0.034811</td>\n",
              "      <td>-0.032414</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.055510</td>\n",
              "      <td>0.068498</td>\n",
              "      <td>0.055427</td>\n",
              "      <td>-0.012711</td>\n",
              "      <td>-0.151866</td>\n",
              "      <td>0.045839</td>\n",
              "      <td>0.033880</td>\n",
              "      <td>-0.038074</td>\n",
              "      <td>Benign</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48336 rows × 258 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              0         1         2         3         4         5         6  \\\n",
              "0      0.021149  0.021297  0.006471 -0.049341  0.009620  0.007508 -0.000810   \n",
              "1      0.021149  0.021297  0.006471 -0.049341  0.009620  0.007508 -0.000810   \n",
              "2      0.021149  0.021297  0.006471 -0.049341  0.009620  0.007508 -0.000810   \n",
              "3      0.021149  0.021297  0.006471 -0.049341  0.009620  0.007508 -0.000810   \n",
              "4      0.021149  0.021297  0.006471 -0.049341  0.009620  0.007508 -0.000810   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "48331  0.004312  0.072504 -0.030171  0.001916  0.043860  0.004750 -0.000360   \n",
              "48332  0.007070  0.017005 -0.011894  0.010123  0.006845 -0.034696 -0.007742   \n",
              "48333  0.008096  0.016402 -0.010737  0.010703  0.006700 -0.034409 -0.007028   \n",
              "48334 -0.009642  0.016289 -0.017025 -0.006309  0.023712 -0.038323  0.019468   \n",
              "48335  0.003370  0.063518 -0.029434  0.001184  0.046182 -0.002004 -0.003866   \n",
              "\n",
              "              7         8         9  ...       248       249       250  \\\n",
              "0     -0.168524 -0.007889  0.023919  ... -0.038401 -0.013742  0.044161   \n",
              "1     -0.168524 -0.007889  0.023919  ... -0.038401 -0.013742  0.044161   \n",
              "2     -0.168524 -0.007889  0.023919  ... -0.038401 -0.013742  0.044161   \n",
              "3     -0.168524 -0.007889  0.023919  ... -0.038401 -0.013742  0.044161   \n",
              "4     -0.168524 -0.007889  0.023919  ... -0.038401 -0.013742  0.044161   \n",
              "...         ...       ...       ...  ...       ...       ...       ...   \n",
              "48331 -0.164642  0.039304 -0.045633  ... -0.053657  0.076697  0.061742   \n",
              "48332 -0.139460 -0.002645  0.059991  ... -0.047402  0.015132  0.006021   \n",
              "48333 -0.139263 -0.000572  0.060527  ... -0.046473  0.016642  0.004763   \n",
              "48334 -0.151655 -0.017344  0.063859  ... -0.036864  0.006375  0.023050   \n",
              "48335 -0.160021  0.034811 -0.032414  ... -0.055510  0.068498  0.055427   \n",
              "\n",
              "            251       252       253       254       255          Attack  Label  \n",
              "0     -0.037521 -0.095929 -0.018112 -0.013422  0.001110            DDoS      1  \n",
              "1     -0.037521 -0.095929 -0.018112 -0.013422  0.001110            DDoS      1  \n",
              "2     -0.037521 -0.095929 -0.018112 -0.013422  0.001110  Reconnaissance      1  \n",
              "3     -0.037521 -0.095929 -0.018112 -0.013422  0.001110            DDoS      1  \n",
              "4     -0.037521 -0.095929 -0.018112 -0.013422  0.001110            DDoS      1  \n",
              "...         ...       ...       ...       ...       ...             ...    ...  \n",
              "48331 -0.007181 -0.154663  0.043798  0.032555 -0.036224          Benign      0  \n",
              "48332 -0.034803 -0.140990  0.049975  0.007324 -0.000731          Benign      0  \n",
              "48333 -0.035007 -0.139795  0.049656  0.006505 -0.001800          Benign      0  \n",
              "48334 -0.005733 -0.114326  0.021652  0.032550 -0.016438          Benign      0  \n",
              "48335 -0.012711 -0.151866  0.045839  0.033880 -0.038074          Benign      0  \n",
              "\n",
              "[48336 rows x 258 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ScEk1y_TzzX"
      },
      "source": [
        "# Embeddings CBLOF  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "ZYABKzdrTGas"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dgl\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "import gc\n",
        "\n",
        "from tqdm import tqdm\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RkFS_-dcTJeK"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "62BUDLtO4mla"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyod in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (2.0.4)\n",
            "Requirement already satisfied: joblib in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.4.2)\n",
            "Requirement already satisfied: matplotlib in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (3.7.5)\n",
            "Requirement already satisfied: numpy>=1.19 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.24.1)\n",
            "Requirement already satisfied: numba>=0.51 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (0.58.1)\n",
            "Requirement already satisfied: scipy>=1.5.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from pyod) (1.3.2)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from numba>=0.51->pyod) (0.41.1)\n",
            "Requirement already satisfied: importlib-metadata in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from numba>=0.51->pyod) (8.5.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from scikit-learn>=0.22.0->pyod) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (2.9.0.post0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from matplotlib->pyod) (6.4.5)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from importlib-resources>=3.2.0->matplotlib->pyod) (3.20.2)\n",
            "Requirement already satisfied: six>=1.5 in /media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib->pyod) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pyod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "2i48uLj74mla",
        "outputId": "a0dd33ee-824d-4328-a960-e656e3aaf0ea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 1/36 [00:02<01:42,  2.92s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  6%|▌         | 2/36 [00:04<01:06,  1.95s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  8%|▊         | 3/36 [00:05<00:52,  1.58s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 11%|█         | 4/36 [00:06<00:44,  1.40s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 14%|█▍        | 5/36 [00:07<00:40,  1.31s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 17%|█▋        | 6/36 [00:08<00:36,  1.22s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 19%|█▉        | 7/36 [00:09<00:35,  1.21s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 22%|██▏       | 8/36 [00:11<00:34,  1.22s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 25%|██▌       | 9/36 [00:12<00:34,  1.26s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 28%|██▊       | 10/36 [00:13<00:31,  1.22s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 31%|███       | 11/36 [00:14<00:30,  1.22s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 33%|███▎      | 12/36 [00:15<00:27,  1.14s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 36%|███▌      | 13/36 [00:16<00:26,  1.14s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 39%|███▉      | 14/36 [00:18<00:25,  1.15s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 42%|████▏     | 15/36 [00:19<00:24,  1.15s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 44%|████▍     | 16/36 [00:20<00:22,  1.12s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 47%|████▋     | 17/36 [00:21<00:20,  1.09s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 50%|█████     | 18/36 [00:22<00:19,  1.09s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 53%|█████▎    | 19/36 [00:23<00:19,  1.16s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 56%|█████▌    | 20/36 [00:25<00:19,  1.22s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 58%|█████▊    | 21/36 [00:26<00:18,  1.20s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 61%|██████    | 22/36 [00:27<00:16,  1.18s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 64%|██████▍   | 23/36 [00:28<00:15,  1.17s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 67%|██████▋   | 24/36 [00:29<00:14,  1.19s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 69%|██████▉   | 25/36 [00:30<00:12,  1.17s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 72%|███████▏  | 26/36 [00:32<00:11,  1.17s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 75%|███████▌  | 27/36 [00:33<00:10,  1.18s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 78%|███████▊  | 28/36 [00:34<00:09,  1.17s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 81%|████████  | 29/36 [00:35<00:08,  1.16s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 83%|████████▎ | 30/36 [00:36<00:07,  1.17s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 86%|████████▌ | 31/36 [00:38<00:06,  1.27s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 89%|████████▉ | 32/36 [00:39<00:05,  1.28s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 92%|█████████▏| 33/36 [00:40<00:03,  1.30s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 94%|█████████▍| 34/36 [00:41<00:02,  1.25s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 97%|█████████▋| 35/36 [00:43<00:01,  1.26s/it]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "100%|██████████| 36/36 [00:44<00:00,  1.24s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 9, 'con': 0.2}\n",
            "0.34682515453882945\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0223    0.7407    0.0433       324\n",
            "           1     0.9916    0.4839    0.6504     20392\n",
            "\n",
            "    accuracy                         0.4879     20716\n",
            "   macro avg     0.5069    0.6123    0.3468     20716\n",
            "weighted avg     0.9764    0.4879    0.6409     20716\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "n_est = [2,3,5,7,9,10]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rK-Rng9q4mla",
        "outputId": "1796db22-cfb8-4bf8-9004-6420c08c3399"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "  0%|          | 0/36 [00:02<?, ?it/s]\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Could not form valid cluster separation. Please change n_clusters or change clustering method",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[39], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n_est, con \u001b[38;5;129;01min\u001b[39;00m tqdm(params):\n\u001b[1;32m      8\u001b[0m     clf_if \u001b[38;5;241m=\u001b[39m CBLOF(n_clusters\u001b[38;5;241m=\u001b[39mn_est, contamination\u001b[38;5;241m=\u001b[39mcon)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mclf_if\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormal_train_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf_if\u001b[38;5;241m.\u001b[39mpredict(test_samples)\n\u001b[1;32m     11\u001b[0m     test_pred \u001b[38;5;241m=\u001b[39m y_pred\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/pyod/models/cblof.py:192\u001b[0m, in \u001b[0;36mCBLOF.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe chosen clustering for CBLOF forms \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m clusters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    188\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich is inconsistent with n_clusters (\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    189\u001b[0m                   \u001b[38;5;28mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters_, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_clusters))\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_cluster_centers(X, n_features)\n\u001b[0;32m--> 192\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_small_large_clusters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_scores_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decision_function(X,\n\u001b[1;32m    195\u001b[0m                                                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcluster_labels_)\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_decision_scores()\n",
            "File \u001b[0;32m/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/pyod/models/cblof.py:290\u001b[0m, in \u001b[0;36mCBLOF._set_small_large_clusters\u001b[0;34m(self, n_samples)\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clustering_threshold \u001b[38;5;241m=\u001b[39m beta_list[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not form valid cluster separation. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    291\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchange n_clusters or change clustering method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmall_cluster_labels_ \u001b[38;5;241m=\u001b[39m sorted_cluster_indices[\n\u001b[1;32m    294\u001b[0m                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clustering_threshold:]\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlarge_cluster_labels_ \u001b[38;5;241m=\u001b[39m sorted_cluster_indices[\n\u001b[1;32m    296\u001b[0m                              \u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clustering_threshold]\n",
            "\u001b[0;31mValueError\u001b[0m: Could not form valid cluster separation. Please change n_clusters or change clustering method"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHSOcEhH4mlb"
      },
      "outputs": [],
      "source": [
        "###  CBLOF RAW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A--j-9Cu4mlb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "-D3nCuXX4mlb"
      },
      "outputs": [],
      "source": [
        "df_raw_train = pd.concat([X_train.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_train], axis=1)\n",
        "df_raw_test = pd.concat([X_test.drop(columns=[\"IPV4_SRC_ADDR\",\"IPV4_DST_ADDR\", \"h\"]), y_test], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "8Zr57GFE4mlb"
      },
      "outputs": [],
      "source": [
        "raw_benign_train_samples = df_raw_train[df_raw_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "raw_normal_train_samples = df_raw_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "raw_train_labels = df_raw_train[\"Label\"]\n",
        "raw_test_labels = df_raw_test[\"Label\"]\n",
        "\n",
        "raw_test_samples = df_raw_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "u_l1Vz8S4mlb",
        "outputId": "c1b8d03c-7105-42d9-f49a-bba4ff4905a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/36 [00:00<?, ?it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 19%|█▉        | 7/36 [00:01<00:05,  5.27it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 22%|██▏       | 8/36 [00:01<00:05,  5.10it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 25%|██▌       | 9/36 [00:01<00:05,  5.02it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 28%|██▊       | 10/36 [00:01<00:05,  4.95it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 31%|███       | 11/36 [00:02<00:05,  4.88it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 33%|███▎      | 12/36 [00:02<00:04,  4.85it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 36%|███▌      | 13/36 [00:02<00:04,  4.80it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 39%|███▉      | 14/36 [00:02<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 42%|████▏     | 15/36 [00:03<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 44%|████▍     | 16/36 [00:03<00:04,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 47%|████▋     | 17/36 [00:03<00:03,  4.81it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 50%|█████     | 18/36 [00:03<00:03,  4.79it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 53%|█████▎    | 19/36 [00:03<00:03,  4.74it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 56%|█████▌    | 20/36 [00:04<00:03,  4.69it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 58%|█████▊    | 21/36 [00:04<00:03,  4.65it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 61%|██████    | 22/36 [00:04<00:03,  4.60it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 64%|██████▍   | 23/36 [00:04<00:02,  4.36it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 67%|██████▋   | 24/36 [00:05<00:02,  4.40it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 69%|██████▉   | 25/36 [00:05<00:02,  4.45it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 72%|███████▏  | 26/36 [00:05<00:02,  4.46it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 75%|███████▌  | 27/36 [00:05<00:02,  4.48it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 78%|███████▊  | 28/36 [00:05<00:01,  4.42it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 81%|████████  | 29/36 [00:06<00:01,  4.41it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 83%|████████▎ | 30/36 [00:06<00:01,  4.47it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 86%|████████▌ | 31/36 [00:06<00:01,  4.45it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 89%|████████▉ | 32/36 [00:06<00:00,  4.43it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 92%|█████████▏| 33/36 [00:07<00:00,  4.43it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 94%|█████████▍| 34/36 [00:07<00:00,  4.44it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            " 97%|█████████▋| 35/36 [00:07<00:00,  4.40it/s]/media/ssd/test/gnn_cuda_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  super()._check_params_vs_input(X, default_n_init=10)\n",
            "100%|██████████| 36/36 [00:07<00:00,  4.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.2}\n",
            "0.3971858513564739\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.0294    0.7949    0.0566        39\n",
            "           1     0.9945    0.5864    0.7378      2478\n",
            "\n",
            "    accuracy                         0.5896      2517\n",
            "   macro avg     0.5119    0.6906    0.3972      2517\n",
            "weighted avg     0.9796    0.5896    0.7272      2517\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-_InJ1-4mlc",
        "outputId": "e22139e6-d1cf-46e1-adf3-f0dc9b499244"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [20:42<00:00, 34.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 2}\n",
            "0.8618432811826696\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9591    0.9806    0.9697    499068\n",
            "           1     0.8287    0.6916    0.7540     67744\n",
            "\n",
            "    accuracy                         0.9461    566812\n",
            "   macro avg     0.8939    0.8361    0.8618    566812\n",
            "weighted avg     0.9435    0.9461    0.9439    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [2,3,5,7,9,10]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = CBLOF(n_clusters=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GneWZNtq4mlc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd0-H7UT4mlc"
      },
      "outputs": [],
      "source": [
        "# HBOS  Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a34ZbzAX4mld"
      },
      "outputs": [],
      "source": [
        "benign_train_samples = df_train[df_train.Label == 0].drop(columns=[\"Label\", \"Attack\"])\n",
        "normal_train_samples = df_train.drop(columns=[\"Label\", \"Attack\"])\n",
        "\n",
        "train_labels = df_train[\"Label\"]\n",
        "test_labels = df_test[\"Label\"]\n",
        "\n",
        "test_samples = df_test.drop(columns=[\"Label\", \"Attack\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sDquxErU4mld"
      },
      "outputs": [],
      "source": [
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SG5Hcs9r4mld"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLBIT-Rc4mld",
        "outputId": "8162929e-4879-40e2-a040-afc57eafe7c5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [19:29<00:00, 32.49s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.01}\n",
            "0.945069359337394\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9845    0.9897    0.9871    996643\n",
            "           1     0.9213    0.8855    0.9030    135488\n",
            "\n",
            "    accuracy                         0.9772   1132131\n",
            "   macro avg     0.9529    0.9376    0.9451   1132131\n",
            "weighted avg     0.9769    0.9772    0.9770   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.hbos import HBOS\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDcX0mma4mld",
        "outputId": "a2b64cfc-d413-4ba0-9f24-b4935343c315"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [21:10<00:00, 35.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 5, 'con': 0.1}\n",
            "0.9189314026948445\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9705    0.9945    0.9824    996643\n",
            "           1     0.9503    0.7779    0.8555    135488\n",
            "\n",
            "    accuracy                         0.9686   1132131\n",
            "   macro avg     0.9604    0.8862    0.9189   1132131\n",
            "weighted avg     0.9681    0.9686    0.9672   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRUOrQqB4mle"
      },
      "outputs": [],
      "source": [
        "##  HBOS  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sZfAnER4mle",
        "outputId": "6e9cb145-8540-4aa7-8ed1-fc9aca495b07"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [02:09<00:00,  3.59s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 30, 'con': 0.04}\n",
            "0.8627757960209628\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9715    0.9601    0.9658    499068\n",
            "           1     0.7294    0.7928    0.7598     67744\n",
            "\n",
            "    accuracy                         0.9401    566812\n",
            "   macro avg     0.8505    0.8765    0.8628    566812\n",
            "weighted avg     0.9426    0.9401    0.9412    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.cblof import CBLOF\n",
        "\n",
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_b = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_b.fit(raw_benign_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "   \n",
        "    y_pred = clf_b.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_b\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5A-gLN34mle",
        "outputId": "8a6dfd26-a45b-4ce3-8d85-1b61652e7f90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [02:14<00:00,  3.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 5}\n",
            "0.7882018992795334\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9766    0.8943    0.9337    499068\n",
            "           1     0.5197    0.8422    0.6427     67744\n",
            "\n",
            "    accuracy                         0.8881    566812\n",
            "   macro avg     0.7481    0.8683    0.7882    566812\n",
            "weighted avg     0.9220    0.8881    0.8989    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "contamination = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, contamination))\n",
        "score = -1\n",
        "bs = None\n",
        "for n_est, con in tqdm(params):\n",
        "    \n",
        "    try:\n",
        "        clf_if = HBOS(n_bins=n_est, contamination=con)\n",
        "        clf_if.fit(raw_normal_train_samples)\n",
        "    except ValueError as e:\n",
        "        print(n_est)\n",
        "        continue  \n",
        "    \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0ZCfgyi4mle"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbDOqrcy4mle"
      },
      "outputs": [],
      "source": [
        "##  PCA  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDCu7S6i4mle"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nga82Fw_4mle",
        "outputId": "0fe52043-af21-45c1-a404-040ab5845efc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [29:47<00:00, 49.66s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.001}\n",
            "0.9442956641768174\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9770    0.9988    0.9878    996643\n",
            "           1     0.9896    0.8267    0.9008    135488\n",
            "\n",
            "    accuracy                         0.9782   1132131\n",
            "   macro avg     0.9833    0.9127    0.9443   1132131\n",
            "weighted avg     0.9785    0.9782    0.9774   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyod.models.pca import PCA\n",
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sg6AcAUW4mlf",
        "outputId": "a9949458-96cf-44dc-b4f6-c73458cb2719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [32:26<00:00, 54.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 10, 'con': 0.1}\n",
            "0.9256946497974641\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9723    0.9955    0.9838    996643\n",
            "           1     0.9598    0.7916    0.8676    135488\n",
            "\n",
            "    accuracy                         0.9711   1132131\n",
            "   macro avg     0.9661    0.8935    0.9257   1132131\n",
            "weighted avg     0.9708    0.9711    0.9699   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSoyZpDu4mlf"
      },
      "outputs": [],
      "source": [
        "##  PCA  RAw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hKgicW14mlf",
        "outputId": "16c93b66-4eac-4d40-d5ce-96f3b3a5b3bb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [07:28<00:00, 12.47s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.1}\n",
            "0.7684270275042566\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9639    0.9009    0.9313    499068\n",
            "           1     0.5071    0.7513    0.6055     67744\n",
            "\n",
            "    accuracy                         0.8830    566812\n",
            "   macro avg     0.7355    0.8261    0.7684    566812\n",
            "weighted avg     0.9093    0.8830    0.8924    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples)\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAdfwnlP4mlf",
        "outputId": "ddc9c2b4-a3b6-4ab6-cc74-7ed93ca23d22"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 36/36 [08:04<00:00, 13.46s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 10}\n",
            "0.7376147683157477\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9622    0.8744    0.9162    499068\n",
            "           1     0.4466    0.7471    0.5590     67744\n",
            "\n",
            "    accuracy                         0.8591    566812\n",
            "   macro avg     0.7044    0.8107    0.7376    566812\n",
            "weighted avg     0.9006    0.8591    0.8735    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [5,10,15,20,25,30]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = PCA(n_components=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples)\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples)\n",
        "    test_pred = y_pred\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdfI45oD4mlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSNV8IRT4mlg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yi8SO3tL4mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Emb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9D0m4vb04mlg",
        "outputId": "bd5a55e6-ac70-4943-9b28-92474b5fb9e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [3:09:47<00:00, 474.46s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.001}\n",
            "0.9538863735449246\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9805    0.9992    0.9897    996643\n",
            "           1     0.9928    0.8538    0.9180    135488\n",
            "\n",
            "    accuracy                         0.9818   1132131\n",
            "   macro avg     0.9866    0.9265    0.9539   1132131\n",
            "weighted avg     0.9820    0.9818    0.9812   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(benign_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCj-3u4t4mlg",
        "outputId": "5f6b1720-9662-4704-ba96-dd57ee32a900"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [3:31:56<00:00, 529.86s/it]  \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 50, 'con': 0.2}\n",
            "0.8110535459623227\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9878    0.8952    0.9392    996643\n",
            "           1     0.5436    0.9184    0.6829    135488\n",
            "\n",
            "    accuracy                         0.8979   1132131\n",
            "   macro avg     0.7657    0.9068    0.8111   1132131\n",
            "weighted avg     0.9346    0.8979    0.9085   1132131\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(normal_train_samples)\n",
        "    y_pred = clf_if.predict(test_samples)\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                       \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOIn_Kr44mlg"
      },
      "outputs": [],
      "source": [
        "##  IF  Raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_60yAo34mlg",
        "outputId": "354e56cd-ee22-4538-ba6f-43c1d67eb648"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [19:12<00:00, 48.03s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'n_estimators': 20, 'con': 0.05}\n",
            "0.8176793439704795\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9599    0.9494    0.9547    499068\n",
            "           1     0.6553    0.7082    0.6807     67744\n",
            "\n",
            "    accuracy                         0.9206    566812\n",
            "   macro avg     0.8076    0.8288    0.8177    566812\n",
            "weighted avg     0.9235    0.9206    0.9219    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_benign_train_samples.to_numpy())\n",
        "   \n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est,\n",
        "                        \"con\": con\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "  \n",
        "\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xNKBA7X4mlh",
        "outputId": "cd0ee1c5-5394-4e2b-efde-1f58bf922282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 24/24 [20:38<00:00, 51.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "benign only\n",
            "{'n_estimators': 100}\n",
            "0.7409370706714709\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9633    0.8755    0.9173    499068\n",
            "           1     0.4512    0.7539    0.5646     67744\n",
            "\n",
            "    accuracy                         0.8610    566812\n",
            "   macro avg     0.7072    0.8147    0.7409    566812\n",
            "weighted avg     0.9021    0.8610    0.8751    566812\n",
            "\n"
          ]
        }
      ],
      "source": [
        "n_est = [20, 50, 100, 150]\n",
        "cont = [0.001, 0.01, 0.04, 0.05, 0.1, 0.2]\n",
        "params = list(itertools.product(n_est, cont))\n",
        "score = -1\n",
        "bs = None\n",
        "\n",
        "for n_est, con in tqdm(params):\n",
        "    clf_if = IsolationForest(n_estimators=n_est, contamination=con)\n",
        "    clf_if.fit(raw_normal_train_samples.to_numpy())\n",
        "\n",
        "    y_pred = clf_if.predict(raw_test_samples.to_numpy())\n",
        "    test_pred = list(map(lambda x : 0 if x == 1 else 1, y_pred))\n",
        "\n",
        "    f1 = f1_score(raw_test_labels, test_pred, average='macro')\n",
        "\n",
        "    if f1 > score:\n",
        "        score = f1\n",
        "        best_params = {'n_estimators': n_est\n",
        "                }\n",
        "        bs = test_pred\n",
        "    del clf_if\n",
        "    gc.collect()\n",
        "\n",
        "        \n",
        "\n",
        "print(\"benign only\")\n",
        "print(best_params)\n",
        "print(score)\n",
        "print(classification_report(raw_test_labels, bs, digits=4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HYBqJ8y14mlh"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gnn_cuda_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
